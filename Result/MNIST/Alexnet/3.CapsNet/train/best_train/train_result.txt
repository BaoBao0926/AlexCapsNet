Epoch 0:
Total Loss: 55.597267150878906
Running time: 45.70345973968506
learning rate is 0.001
next epoch lr is 0.000995, lr_dacay is 0.995


Epoch 1:
Total Loss: 16.49283790588379
Running time: 45.71618723869324
learning rate is 0.000995
next epoch lr is 0.000990025, lr_dacay is 0.995


Epoch 2:
Total Loss: 11.516036033630371
Running time: 45.67790651321411
learning rate is 0.000990025
next epoch lr is 0.000985074875, lr_dacay is 0.995


Epoch 3:
Total Loss: 8.308730125427246
Running time: 45.653032064437866
learning rate is 0.000985074875
next epoch lr is 0.000980149500625, lr_dacay is 0.995


Epoch 4:
Total Loss: 5.58926248550415
Running time: 45.63780879974365
learning rate is 0.000980149500625
next epoch lr is 0.000975248753121875, lr_dacay is 0.995


Epoch 5:
Total Loss: 4.417048454284668
Running time: 45.5094530582428
learning rate is 0.000975248753121875
next epoch lr is 0.0009703725093562657, lr_dacay is 0.995


Epoch 6:
Total Loss: 3.6182971000671387
Running time: 45.3997106552124
learning rate is 0.0009703725093562657
next epoch lr is 0.0009655206468094843, lr_dacay is 0.995


Epoch 7:
Total Loss: 2.9222192764282227
Running time: 45.34862971305847
learning rate is 0.0009655206468094843
next epoch lr is 0.0009606930435754369, lr_dacay is 0.995


Epoch 8:
Total Loss: 3.1526296138763428
Running time: 45.83238744735718
learning rate is 0.0009606930435754369
next epoch lr is 0.0009558895783575597, lr_dacay is 0.995


Epoch 9:
Total Loss: 1.8659255504608154
Running time: 45.30925107002258
learning rate is 0.0009558895783575597
next epoch lr is 0.0009511101304657719, lr_dacay is 0.995


Epoch 10:
Total Loss: 2.4260287284851074
Running time: 45.63894557952881
learning rate is 0.0009511101304657719
next epoch lr is 0.000946354579813443, lr_dacay is 0.995


Epoch 11:
Total Loss: 2.0360541343688965
Running time: 45.449238538742065
learning rate is 0.000946354579813443
next epoch lr is 0.0009416228069143757, lr_dacay is 0.995


Epoch 12:
Total Loss: 1.5580828189849854
Running time: 45.62730550765991
learning rate is 0.0009416228069143757
next epoch lr is 0.0009369146928798038, lr_dacay is 0.995


Epoch 13:
Total Loss: 1.7103980779647827
Running time: 45.57067370414734
learning rate is 0.0009369146928798038
next epoch lr is 0.0009322301194154048, lr_dacay is 0.995


Epoch 14:
Total Loss: 1.5667569637298584
Running time: 45.59709548950195
learning rate is 0.0009322301194154048
next epoch lr is 0.0009275689688183278, lr_dacay is 0.995


Epoch 15:
Total Loss: 1.1466962099075317
Running time: 45.59066438674927
learning rate is 0.0009275689688183278
next epoch lr is 0.0009229311239742361, lr_dacay is 0.995


Epoch 16:
Total Loss: 1.3752412796020508
Running time: 45.56619930267334
learning rate is 0.0009229311239742361
next epoch lr is 0.0009183164683543649, lr_dacay is 0.995


Epoch 17:
Total Loss: 1.2343343496322632
Running time: 45.27328705787659
learning rate is 0.0009183164683543649
next epoch lr is 0.0009137248860125931, lr_dacay is 0.995


Epoch 18:
Total Loss: 0.9513635635375977
Running time: 45.61091661453247
learning rate is 0.0009137248860125931
next epoch lr is 0.0009091562615825302, lr_dacay is 0.995


Epoch 19:
Total Loss: 1.23920476436615
Running time: 45.453439474105835
learning rate is 0.0009091562615825302
next epoch lr is 0.0009046104802746175, lr_dacay is 0.995


Epoch 20:
Total Loss: 0.9732323884963989
Running time: 45.456955671310425
learning rate is 0.0009046104802746175
next epoch lr is 0.0009000874278732445, lr_dacay is 0.995


Epoch 21:
Total Loss: 0.8680580258369446
Running time: 45.29886794090271
learning rate is 0.0009000874278732445
next epoch lr is 0.0008955869907338783, lr_dacay is 0.995


Epoch 22:
Total Loss: 0.8622360825538635
Running time: 45.27345418930054
learning rate is 0.0008955869907338783
next epoch lr is 0.0008911090557802089, lr_dacay is 0.995


Epoch 23:
Total Loss: 0.7915652394294739
Running time: 45.61324715614319
learning rate is 0.0008911090557802089
next epoch lr is 0.0008866535105013078, lr_dacay is 0.995


Epoch 24:
Total Loss: 1.3862441778182983
Running time: 45.640748739242554
learning rate is 0.0008866535105013078
next epoch lr is 0.0008822202429488013, lr_dacay is 0.995


Epoch 25:
Total Loss: 0.6801987886428833
Running time: 45.57454967498779
learning rate is 0.0008822202429488013
next epoch lr is 0.0008778091417340573, lr_dacay is 0.995


Epoch 26:
Total Loss: 0.5390719175338745
Running time: 45.38808846473694
learning rate is 0.0008778091417340573
next epoch lr is 0.000873420096025387, lr_dacay is 0.995


Epoch 27:
Total Loss: 0.7940826416015625
Running time: 45.45585536956787
learning rate is 0.000873420096025387
next epoch lr is 0.0008690529955452601, lr_dacay is 0.995


Epoch 28:
Total Loss: 0.7896169424057007
Running time: 45.30637192726135
learning rate is 0.0008690529955452601
next epoch lr is 0.0008647077305675338, lr_dacay is 0.995


Epoch 29:
Total Loss: 0.8610837459564209
Running time: 45.7361958026886
learning rate is 0.0008647077305675338
next epoch lr is 0.0008603841919146961, lr_dacay is 0.995


Epoch 30:
Total Loss: 0.7356821894645691
Running time: 45.822277784347534
learning rate is 0.0008603841919146961
next epoch lr is 0.0008560822709551226, lr_dacay is 0.995


Epoch 31:
Total Loss: 0.5799906253814697
Running time: 45.322999477386475
learning rate is 0.0008560822709551226
next epoch lr is 0.000851801859600347, lr_dacay is 0.995


Epoch 32:
Total Loss: 0.46038901805877686
Running time: 45.605653285980225
learning rate is 0.000851801859600347
next epoch lr is 0.0008475428503023452, lr_dacay is 0.995


Epoch 33:
Total Loss: 0.8019031882286072
Running time: 45.52740740776062
learning rate is 0.0008475428503023452
next epoch lr is 0.0008433051360508335, lr_dacay is 0.995


Epoch 34:
Total Loss: 0.6043748259544373
Running time: 45.66037368774414
learning rate is 0.0008433051360508335
next epoch lr is 0.0008390886103705794, lr_dacay is 0.995


Epoch 35:
Total Loss: 0.4790177345275879
Running time: 45.826435804367065
learning rate is 0.0008390886103705794
next epoch lr is 0.0008348931673187264, lr_dacay is 0.995


Epoch 36:
Total Loss: 0.534236490726471
Running time: 45.50552010536194
learning rate is 0.0008348931673187264
next epoch lr is 0.0008307187014821328, lr_dacay is 0.995


Epoch 37:
Total Loss: 0.5074095129966736
Running time: 45.72234106063843
learning rate is 0.0008307187014821328
next epoch lr is 0.0008265651079747222, lr_dacay is 0.995


Epoch 38:
Total Loss: 0.6947323679924011
Running time: 45.43150973320007
learning rate is 0.0008265651079747222
next epoch lr is 0.0008224322824348485, lr_dacay is 0.995


Epoch 39:
Total Loss: 0.4424494802951813
Running time: 45.69913387298584
learning rate is 0.0008224322824348485
next epoch lr is 0.0008183201210226743, lr_dacay is 0.995


Epoch 40:
Total Loss: 0.47436219453811646
Running time: 45.55428767204285
learning rate is 0.0008183201210226743
next epoch lr is 0.0008142285204175609, lr_dacay is 0.995


Epoch 41:
Total Loss: 0.447539746761322
Running time: 45.516918659210205
learning rate is 0.0008142285204175609
next epoch lr is 0.0008101573778154731, lr_dacay is 0.995


Epoch 42:
Total Loss: 0.2478404939174652
Running time: 45.280574560165405
learning rate is 0.0008101573778154731
next epoch lr is 0.0008061065909263957, lr_dacay is 0.995


Epoch 43:
Total Loss: 0.7360717058181763
Running time: 45.46205759048462
learning rate is 0.0008061065909263957
next epoch lr is 0.0008020760579717638, lr_dacay is 0.995


Epoch 44:
Total Loss: 0.48219233751296997
Running time: 45.364110708236694
learning rate is 0.0008020760579717638
next epoch lr is 0.000798065677681905, lr_dacay is 0.995


Epoch 45:
Total Loss: 0.22246018052101135
Running time: 45.2922887802124
learning rate is 0.000798065677681905
next epoch lr is 0.0007940753492934955, lr_dacay is 0.995


Epoch 46:
Total Loss: 0.3481495976448059
Running time: 45.52402591705322
learning rate is 0.0007940753492934955
next epoch lr is 0.000790104972547028, lr_dacay is 0.995


Epoch 47:
Total Loss: 0.6771456599235535
Running time: 45.32113838195801
learning rate is 0.000790104972547028
next epoch lr is 0.0007861544476842928, lr_dacay is 0.995


Epoch 48:
Total Loss: 0.3694354295730591
Running time: 45.7250702381134
learning rate is 0.0007861544476842928
next epoch lr is 0.0007822236754458713, lr_dacay is 0.995


Epoch 49:
Total Loss: 0.3027077615261078
Running time: 45.6611647605896
learning rate is 0.0007822236754458713
next epoch lr is 0.0007783125570686419, lr_dacay is 0.995


Epoch 50:
Total Loss: 0.5266553163528442
Running time: 45.47461676597595
learning rate is 0.0007783125570686419
next epoch lr is 0.0007744209942832988, lr_dacay is 0.995


Epoch 51:
Total Loss: 0.5310894250869751
Running time: 45.502745151519775
learning rate is 0.0007744209942832988
next epoch lr is 0.0007705488893118823, lr_dacay is 0.995


Epoch 52:
Total Loss: 0.35732221603393555
Running time: 45.571640729904175
learning rate is 0.0007705488893118823
next epoch lr is 0.0007666961448653228, lr_dacay is 0.995


Epoch 53:
Total Loss: 0.236840158700943
Running time: 45.462685346603394
learning rate is 0.0007666961448653228
next epoch lr is 0.0007628626641409962, lr_dacay is 0.995


Epoch 54:
Total Loss: 0.26590201258659363
Running time: 45.323426961898804
learning rate is 0.0007628626641409962
next epoch lr is 0.0007590483508202912, lr_dacay is 0.995


Epoch 55:
Total Loss: 0.35250124335289
Running time: 45.67918825149536
learning rate is 0.0007590483508202912
next epoch lr is 0.0007552531090661898, lr_dacay is 0.995


Epoch 56:
Total Loss: 0.4654918611049652
Running time: 45.31018090248108
learning rate is 0.0007552531090661898
next epoch lr is 0.0007514768435208588, lr_dacay is 0.995


Epoch 57:
Total Loss: 0.25132307410240173
Running time: 45.483529806137085
learning rate is 0.0007514768435208588
next epoch lr is 0.0007477194593032545, lr_dacay is 0.995


Epoch 58:
Total Loss: 0.20783856511116028
Running time: 45.58756422996521
learning rate is 0.0007477194593032545
next epoch lr is 0.0007439808620067382, lr_dacay is 0.995


Epoch 59:
Total Loss: 0.2314525991678238
Running time: 45.38182020187378
learning rate is 0.0007439808620067382
next epoch lr is 0.0007402609576967046, lr_dacay is 0.995


Epoch 60:
Total Loss: 0.6825743317604065
Running time: 45.29272198677063
learning rate is 0.0007402609576967046
next epoch lr is 0.000736559652908221, lr_dacay is 0.995


Epoch 61:
Total Loss: 0.27824270725250244
Running time: 45.400450468063354
learning rate is 0.000736559652908221
next epoch lr is 0.0007328768546436799, lr_dacay is 0.995


Epoch 62:
Total Loss: 0.19634084403514862
Running time: 45.636574506759644
learning rate is 0.0007328768546436799
next epoch lr is 0.0007292124703704615, lr_dacay is 0.995


Epoch 63:
Total Loss: 0.4176519513130188
Running time: 45.36448001861572
learning rate is 0.0007292124703704615
next epoch lr is 0.0007255664080186091, lr_dacay is 0.995


Epoch 64:
Total Loss: 0.3175743520259857
Running time: 45.61640501022339
learning rate is 0.0007255664080186091
next epoch lr is 0.0007219385759785161, lr_dacay is 0.995


Epoch 65:
Total Loss: 0.16385991871356964
Running time: 45.503674030303955
learning rate is 0.0007219385759785161
next epoch lr is 0.0007183288830986235, lr_dacay is 0.995


Epoch 66:
Total Loss: 0.36250799894332886
Running time: 45.31607508659363
learning rate is 0.0007183288830986235
next epoch lr is 0.0007147372386831303, lr_dacay is 0.995


Epoch 67:
Total Loss: 0.34125378727912903
Running time: 45.74811911582947
learning rate is 0.0007147372386831303
next epoch lr is 0.0007111635524897147, lr_dacay is 0.995


Epoch 68:
Total Loss: 0.16175714135169983
Running time: 45.69692373275757
learning rate is 0.0007111635524897147
next epoch lr is 0.0007076077347272661, lr_dacay is 0.995


Epoch 69:
Total Loss: 0.37044385075569153
Running time: 45.426814794540405
learning rate is 0.0007076077347272661
next epoch lr is 0.0007040696960536298, lr_dacay is 0.995


Epoch 70:
Total Loss: 0.1605096161365509
Running time: 45.49749159812927
learning rate is 0.0007040696960536298
next epoch lr is 0.0007005493475733617, lr_dacay is 0.995


Epoch 71:
Total Loss: 0.18614409863948822
Running time: 45.57902002334595
learning rate is 0.0007005493475733617
next epoch lr is 0.0006970466008354948, lr_dacay is 0.995


Epoch 72:
Total Loss: 0.37437155842781067
Running time: 45.486387729644775
learning rate is 0.0006970466008354948
next epoch lr is 0.0006935613678313174, lr_dacay is 0.995


Epoch 73:
Total Loss: 0.3865130543708801
Running time: 45.272014141082764
learning rate is 0.0006935613678313174
next epoch lr is 0.0006900935609921607, lr_dacay is 0.995


Epoch 74:
Total Loss: 0.13000193238258362
Running time: 45.38161563873291
learning rate is 0.0006900935609921607
next epoch lr is 0.0006866430931872, lr_dacay is 0.995


Epoch 75:
Total Loss: 0.1229347288608551
Running time: 45.48635172843933
learning rate is 0.0006866430931872
next epoch lr is 0.000683209877721264, lr_dacay is 0.995


Epoch 76:
Total Loss: 0.36840736865997314
Running time: 45.586846113204956
learning rate is 0.000683209877721264
next epoch lr is 0.0006797938283326577, lr_dacay is 0.995


Epoch 77:
Total Loss: 0.20600952208042145
Running time: 45.50058722496033
learning rate is 0.0006797938283326577
next epoch lr is 0.0006763948591909945, lr_dacay is 0.995


Epoch 78:
Total Loss: 0.1246945708990097
Running time: 45.570260763168335
learning rate is 0.0006763948591909945
next epoch lr is 0.0006730128848950395, lr_dacay is 0.995


Epoch 79:
Total Loss: 0.14392496645450592
Running time: 45.66150188446045
learning rate is 0.0006730128848950395
next epoch lr is 0.0006696478204705643, lr_dacay is 0.995


Epoch 80:
Total Loss: 0.3439757823944092
Running time: 45.588064432144165
learning rate is 0.0006696478204705643
next epoch lr is 0.0006662995813682115, lr_dacay is 0.995


Epoch 81:
Total Loss: 0.1917112171649933
Running time: 45.43322229385376
learning rate is 0.0006662995813682115
next epoch lr is 0.0006629680834613704, lr_dacay is 0.995


Epoch 82:
Total Loss: 0.16233454644680023
Running time: 45.394357204437256
learning rate is 0.0006629680834613704
next epoch lr is 0.0006596532430440636, lr_dacay is 0.995


Epoch 83:
Total Loss: 0.24889253079891205
Running time: 45.61130118370056
learning rate is 0.0006596532430440636
next epoch lr is 0.0006563549768288432, lr_dacay is 0.995


Epoch 84:
Total Loss: 0.3273327350616455
Running time: 45.4929473400116
learning rate is 0.0006563549768288432
next epoch lr is 0.000653073201944699, lr_dacay is 0.995


Epoch 85:
Total Loss: 0.18981410562992096
Running time: 45.345409631729126
learning rate is 0.000653073201944699
next epoch lr is 0.0006498078359349755, lr_dacay is 0.995


Epoch 86:
Total Loss: 0.07630997896194458
Running time: 45.61589241027832
learning rate is 0.0006498078359349755
next epoch lr is 0.0006465587967553006, lr_dacay is 0.995


Epoch 87:
Total Loss: 0.17544680833816528
Running time: 45.64876580238342
learning rate is 0.0006465587967553006
next epoch lr is 0.0006433260027715241, lr_dacay is 0.995


Epoch 88:
Total Loss: 0.2980273962020874
Running time: 45.4613471031189
learning rate is 0.0006433260027715241
next epoch lr is 0.0006401093727576665, lr_dacay is 0.995


Epoch 89:
Total Loss: 0.11909180134534836
Running time: 45.533591985702515
learning rate is 0.0006401093727576665
next epoch lr is 0.0006369088258938781, lr_dacay is 0.995


Epoch 90:
Total Loss: 0.06796477735042572
Running time: 45.504562854766846
learning rate is 0.0006369088258938781
next epoch lr is 0.0006337242817644087, lr_dacay is 0.995


Epoch 91:
Total Loss: 0.07960619032382965
Running time: 45.63025784492493
learning rate is 0.0006337242817644087
next epoch lr is 0.0006305556603555866, lr_dacay is 0.995


Epoch 92:
Total Loss: 0.2188708633184433
Running time: 45.80741596221924
learning rate is 0.0006305556603555866
next epoch lr is 0.0006274028820538087, lr_dacay is 0.995


Epoch 93:
Total Loss: 0.25301462411880493
Running time: 45.629255056381226
learning rate is 0.0006274028820538087
next epoch lr is 0.0006242658676435396, lr_dacay is 0.995


Epoch 94:
Total Loss: 0.17418599128723145
Running time: 45.605621576309204
learning rate is 0.0006242658676435396
next epoch lr is 0.0006211445383053219, lr_dacay is 0.995


Epoch 95:
Total Loss: 0.07131968438625336
Running time: 45.569132566452026
learning rate is 0.0006211445383053219
next epoch lr is 0.0006180388156137953, lr_dacay is 0.995


Epoch 96:
Total Loss: 0.16891518235206604
Running time: 45.391706466674805
learning rate is 0.0006180388156137953
next epoch lr is 0.0006149486215357262, lr_dacay is 0.995


Epoch 97:
Total Loss: 0.19471442699432373
Running time: 45.7720148563385
learning rate is 0.0006149486215357262
next epoch lr is 0.0006118738784280476, lr_dacay is 0.995


Epoch 98:
Total Loss: 0.06876124441623688
Running time: 45.46487617492676
learning rate is 0.0006118738784280476
next epoch lr is 0.0006088145090359073, lr_dacay is 0.995


Epoch 99:
Total Loss: 0.12572000920772552
Running time: 45.49543309211731
learning rate is 0.0006088145090359073
next epoch lr is 0.0006057704364907278, lr_dacay is 0.995


Epoch 100:
Total Loss: 0.1979953944683075
Running time: 45.5268075466156
learning rate is 0.0006057704364907278
next epoch lr is 0.0006027415843082742, lr_dacay is 0.995


Epoch 101:
Total Loss: 0.18120278418064117
Running time: 45.62468934059143
learning rate is 0.0006027415843082742
next epoch lr is 0.0005997278763867329, lr_dacay is 0.995


Epoch 102:
Total Loss: 0.08552593737840652
Running time: 45.50392007827759
learning rate is 0.0005997278763867329
next epoch lr is 0.0005967292370047993, lr_dacay is 0.995


Epoch 103:
Total Loss: 0.06413012742996216
Running time: 45.41020894050598
learning rate is 0.0005967292370047993
next epoch lr is 0.0005937455908197753, lr_dacay is 0.995


Epoch 104:
Total Loss: 0.2511116862297058
Running time: 45.561487674713135
learning rate is 0.0005937455908197753
next epoch lr is 0.0005907768628656764, lr_dacay is 0.995


Epoch 105:
Total Loss: 0.1686050295829773
Running time: 45.342050075531006
learning rate is 0.0005907768628656764
next epoch lr is 0.000587822978551348, lr_dacay is 0.995


Epoch 106:
Total Loss: 0.05696294829249382
Running time: 45.48278856277466
learning rate is 0.000587822978551348
next epoch lr is 0.0005848838636585913, lr_dacay is 0.995


Epoch 107:
Total Loss: 0.20742720365524292
Running time: 45.42543888092041
learning rate is 0.0005848838636585913
next epoch lr is 0.0005819594443402983, lr_dacay is 0.995


Epoch 108:
Total Loss: 0.1051785796880722
Running time: 45.40833067893982
learning rate is 0.0005819594443402983
next epoch lr is 0.0005790496471185969, lr_dacay is 0.995


Epoch 109:
Total Loss: 0.048911090940237045
Running time: 45.73281717300415
learning rate is 0.0005790496471185969
next epoch lr is 0.0005761543988830039, lr_dacay is 0.995


Epoch 110:
Total Loss: 0.07703956961631775
Running time: 45.675477504730225
learning rate is 0.0005761543988830039
next epoch lr is 0.0005732736268885889, lr_dacay is 0.995


Epoch 111:
Total Loss: 0.20984585583209991
Running time: 45.7397084236145
learning rate is 0.0005732736268885889
next epoch lr is 0.0005704072587541459, lr_dacay is 0.995


Epoch 112:
Total Loss: 0.13237743079662323
Running time: 45.33511304855347
learning rate is 0.0005704072587541459
next epoch lr is 0.0005675552224603752, lr_dacay is 0.995


Epoch 113:
Total Loss: 0.0726873055100441
Running time: 45.25685000419617
learning rate is 0.0005675552224603752
next epoch lr is 0.0005647174463480733, lr_dacay is 0.995


Epoch 114:
Total Loss: 0.06187526881694794
Running time: 45.66693067550659
learning rate is 0.0005647174463480733
next epoch lr is 0.0005618938591163329, lr_dacay is 0.995


Epoch 115:
Total Loss: 0.09214423596858978
Running time: 45.704524755477905
learning rate is 0.0005618938591163329
next epoch lr is 0.0005590843898207513, lr_dacay is 0.995


Epoch 116:
Total Loss: 0.10080985724925995
Running time: 45.53842735290527
learning rate is 0.0005590843898207513
next epoch lr is 0.0005562889678716475, lr_dacay is 0.995


Epoch 117:
Total Loss: 0.19119150936603546
Running time: 45.54071116447449
learning rate is 0.0005562889678716475
next epoch lr is 0.0005535075230322892, lr_dacay is 0.995


Epoch 118:
Total Loss: 0.1516999751329422
Running time: 45.41908860206604
learning rate is 0.0005535075230322892
next epoch lr is 0.0005507399854171277, lr_dacay is 0.995


Epoch 119:
Total Loss: 0.14650623500347137
Running time: 45.50703716278076
learning rate is 0.0005507399854171277
next epoch lr is 0.0005479862854900421, lr_dacay is 0.995


Epoch 120:
Total Loss: 0.0804736390709877
Running time: 45.41301894187927
learning rate is 0.0005479862854900421
next epoch lr is 0.0005452463540625918, lr_dacay is 0.995


Epoch 121:
Total Loss: 0.06712954491376877
Running time: 45.32711482048035
learning rate is 0.0005452463540625918
next epoch lr is 0.0005425201222922788, lr_dacay is 0.995


Epoch 122:
Total Loss: 0.08732352405786514
Running time: 45.63071322441101
learning rate is 0.0005425201222922788
next epoch lr is 0.0005398075216808175, lr_dacay is 0.995


Epoch 123:
Total Loss: 0.06495684385299683
Running time: 45.615535497665405
learning rate is 0.0005398075216808175
next epoch lr is 0.0005371084840724133, lr_dacay is 0.995


Epoch 124:
Total Loss: 0.2488674521446228
Running time: 45.407220125198364
learning rate is 0.0005371084840724133
next epoch lr is 0.0005344229416520513, lr_dacay is 0.995


Epoch 125:
Total Loss: 0.11429625749588013
Running time: 45.37319231033325
learning rate is 0.0005344229416520513
next epoch lr is 0.000531750826943791, lr_dacay is 0.995


Epoch 126:
Total Loss: 0.05823710933327675
Running time: 45.471515417099
learning rate is 0.000531750826943791
next epoch lr is 0.000529092072809072, lr_dacay is 0.995


Epoch 127:
Total Loss: 0.03069312311708927
Running time: 45.31178307533264
learning rate is 0.000529092072809072
next epoch lr is 0.0005264466124450266, lr_dacay is 0.995


Epoch 128:
Total Loss: 0.1338888555765152
Running time: 45.701857566833496
learning rate is 0.0005264466124450266
next epoch lr is 0.0005238143793828015, lr_dacay is 0.995


Epoch 129:
Total Loss: 0.05174274742603302
Running time: 45.42813277244568
learning rate is 0.0005238143793828015
next epoch lr is 0.0005211953074858875, lr_dacay is 0.995


Epoch 130:
Total Loss: 0.07002098113298416
Running time: 45.699803829193115
learning rate is 0.0005211953074858875
next epoch lr is 0.0005185893309484581, lr_dacay is 0.995


Epoch 131:
Total Loss: 0.08603456616401672
Running time: 45.31145763397217
learning rate is 0.0005185893309484581
next epoch lr is 0.0005159963842937158, lr_dacay is 0.995


Epoch 132:
Total Loss: 0.12615574896335602
Running time: 45.435752868652344
learning rate is 0.0005159963842937158
next epoch lr is 0.0005134164023722472, lr_dacay is 0.995


Epoch 133:
Total Loss: 0.17024105787277222
Running time: 45.494346141815186
learning rate is 0.0005134164023722472
next epoch lr is 0.000510849320360386, lr_dacay is 0.995


Epoch 134:
Total Loss: 0.09954363107681274
Running time: 45.304458141326904
learning rate is 0.000510849320360386
next epoch lr is 0.0005082950737585841, lr_dacay is 0.995


Epoch 135:
Total Loss: 0.04635064676403999
Running time: 45.34624719619751
learning rate is 0.0005082950737585841
next epoch lr is 0.0005057535983897911, lr_dacay is 0.995


Epoch 136:
Total Loss: 0.09579325467348099
Running time: 45.604132652282715
learning rate is 0.0005057535983897911
next epoch lr is 0.0005032248303978422, lr_dacay is 0.995


Epoch 137:
Total Loss: 0.0702817365527153
Running time: 45.428483963012695
learning rate is 0.0005032248303978422
next epoch lr is 0.000500708706245853, lr_dacay is 0.995


Epoch 138:
Total Loss: 0.053986165672540665
Running time: 45.72887945175171
learning rate is 0.000500708706245853
next epoch lr is 0.0004982051627146237, lr_dacay is 0.995


Epoch 139:
Total Loss: 0.06328147649765015
Running time: 45.32135057449341
learning rate is 0.0004982051627146237
next epoch lr is 0.0004957141369010506, lr_dacay is 0.995


Epoch 140:
Total Loss: 0.03423672541975975
Running time: 45.52806735038757
learning rate is 0.0004957141369010506
next epoch lr is 0.0004932355662165453, lr_dacay is 0.995


Epoch 141:
Total Loss: 0.06734223663806915
Running time: 45.51492357254028
learning rate is 0.0004932355662165453
next epoch lr is 0.0004907693883854625, lr_dacay is 0.995


Epoch 142:
Total Loss: 0.07272931188344955
Running time: 45.3543496131897
learning rate is 0.0004907693883854625
next epoch lr is 0.0004883155414435352, lr_dacay is 0.995


Epoch 143:
Total Loss: 0.07648148387670517
Running time: 45.692547082901
learning rate is 0.0004883155414435352
next epoch lr is 0.00048587396373631753, lr_dacay is 0.995


Epoch 144:
Total Loss: 0.05851789563894272
Running time: 45.74408745765686
learning rate is 0.00048587396373631753
next epoch lr is 0.00048344459391763597, lr_dacay is 0.995


Epoch 145:
Total Loss: 0.08882386982440948
Running time: 45.41931772232056
learning rate is 0.00048344459391763597
next epoch lr is 0.0004810273709480478, lr_dacay is 0.995


Epoch 146:
Total Loss: 0.05692558363080025
Running time: 45.54375457763672
learning rate is 0.0004810273709480478
next epoch lr is 0.00047862223409330756, lr_dacay is 0.995


Epoch 147:
Total Loss: 0.0964566320180893
Running time: 45.499733209609985
learning rate is 0.00047862223409330756
next epoch lr is 0.000476229122922841, lr_dacay is 0.995


Epoch 148:
Total Loss: 0.055065006017684937
Running time: 45.589834690093994
learning rate is 0.000476229122922841
next epoch lr is 0.0004738479773082268, lr_dacay is 0.995


Epoch 149:
Total Loss: 0.05974477529525757
Running time: 45.343318939208984
learning rate is 0.0004738479773082268
next epoch lr is 0.0004714787374216857, lr_dacay is 0.995


Epoch 150:
Total Loss: 0.03775916248559952
Running time: 45.40935444831848
learning rate is 0.0004714787374216857
next epoch lr is 0.00046912134373457723, lr_dacay is 0.995


Epoch 151:
Total Loss: 0.0643104538321495
Running time: 45.23893594741821
learning rate is 0.00046912134373457723
next epoch lr is 0.00046677573701590436, lr_dacay is 0.995


Epoch 152:
Total Loss: 0.03557062894105911
Running time: 45.23734784126282
learning rate is 0.00046677573701590436
next epoch lr is 0.0004644418583308248, lr_dacay is 0.995


Epoch 153:
Total Loss: 0.07302413880825043
Running time: 45.70292258262634
learning rate is 0.0004644418583308248
next epoch lr is 0.0004621196490391707, lr_dacay is 0.995


Epoch 154:
Total Loss: 0.0360184870660305
Running time: 45.349478244781494
learning rate is 0.0004621196490391707
next epoch lr is 0.00045980905079397486, lr_dacay is 0.995


Epoch 155:
Total Loss: 0.08120346814393997
Running time: 45.7911810874939
learning rate is 0.00045980905079397486
next epoch lr is 0.000457510005540005, lr_dacay is 0.995


Epoch 156:
Total Loss: 0.0684615820646286
Running time: 45.721659660339355
learning rate is 0.000457510005540005
next epoch lr is 0.00045522245551230493, lr_dacay is 0.995


Epoch 157:
Total Loss: 0.04338862746953964
Running time: 45.45067882537842
learning rate is 0.00045522245551230493
next epoch lr is 0.0004529463432347434, lr_dacay is 0.995


Epoch 158:
Total Loss: 0.040359016507864
Running time: 45.64602017402649
learning rate is 0.0004529463432347434
next epoch lr is 0.00045068161151856965, lr_dacay is 0.995


Epoch 159:
Total Loss: 0.03531605377793312
Running time: 45.633400678634644
learning rate is 0.00045068161151856965
next epoch lr is 0.0004484282034609768, lr_dacay is 0.995


Epoch 160:
Total Loss: 0.07866684347391129
Running time: 45.5423526763916
learning rate is 0.0004484282034609768
next epoch lr is 0.0004461860624436719, lr_dacay is 0.995


Epoch 161:
Total Loss: 0.16069599986076355
Running time: 45.63582754135132
learning rate is 0.0004461860624436719
next epoch lr is 0.00044395513213145357, lr_dacay is 0.995


Epoch 162:
Total Loss: 0.046115439385175705
Running time: 45.812512159347534
learning rate is 0.00044395513213145357
next epoch lr is 0.0004417353564707963, lr_dacay is 0.995


Epoch 163:
Total Loss: 0.05833287909626961
Running time: 45.530611515045166
learning rate is 0.0004417353564707963
next epoch lr is 0.00043952667968844234, lr_dacay is 0.995


Epoch 164:
Total Loss: 0.05002520605921745
Running time: 45.315916776657104
learning rate is 0.00043952667968844234
next epoch lr is 0.0004373290462900001, lr_dacay is 0.995


Epoch 165:
Total Loss: 0.026394613087177277
Running time: 45.616594552993774
learning rate is 0.0004373290462900001
next epoch lr is 0.0004351424010585501, lr_dacay is 0.995


Epoch 166:
Total Loss: 0.01590382680296898
Running time: 45.5748450756073
learning rate is 0.0004351424010585501
next epoch lr is 0.00043296668905325734, lr_dacay is 0.995


Epoch 167:
Total Loss: 0.036613576114177704
Running time: 45.3451943397522
learning rate is 0.00043296668905325734
next epoch lr is 0.00043080185560799106, lr_dacay is 0.995


Epoch 168:
Total Loss: 0.0911439061164856
Running time: 45.56883382797241
learning rate is 0.00043080185560799106
next epoch lr is 0.0004286478463299511, lr_dacay is 0.995


Epoch 169:
Total Loss: 0.039603568613529205
Running time: 45.553733587265015
learning rate is 0.0004286478463299511
next epoch lr is 0.00042650460709830134, lr_dacay is 0.995


Epoch 170:
Total Loss: 0.01649777963757515
Running time: 45.634392738342285
learning rate is 0.00042650460709830134
next epoch lr is 0.00042437208406280984, lr_dacay is 0.995


Epoch 171:
Total Loss: 0.07435404509305954
Running time: 45.530985832214355
learning rate is 0.00042437208406280984
next epoch lr is 0.0004222502236424958, lr_dacay is 0.995


Epoch 172:
Total Loss: 0.05568656697869301
Running time: 45.28325796127319
learning rate is 0.0004222502236424958
next epoch lr is 0.0004201389725242833, lr_dacay is 0.995


Epoch 173:
Total Loss: 0.028460731729865074
Running time: 45.379685163497925
learning rate is 0.0004201389725242833
next epoch lr is 0.00041803827766166186, lr_dacay is 0.995


Epoch 174:
Total Loss: 0.023599740117788315
Running time: 45.48883652687073
learning rate is 0.00041803827766166186
next epoch lr is 0.00041594808627335356, lr_dacay is 0.995


Epoch 175:
Total Loss: 0.05760662630200386
Running time: 45.662076234817505
learning rate is 0.00041594808627335356
next epoch lr is 0.0004138683458419868, lr_dacay is 0.995


Epoch 176:
Total Loss: 0.0786902904510498
Running time: 45.509085178375244
learning rate is 0.0004138683458419868
next epoch lr is 0.00041179900411277687, lr_dacay is 0.995


Epoch 177:
Total Loss: 0.05156466364860535
Running time: 45.481898069381714
learning rate is 0.00041179900411277687
next epoch lr is 0.000409740009092213, lr_dacay is 0.995


Epoch 178:
Total Loss: 0.04144018515944481
Running time: 45.464826345443726
learning rate is 0.000409740009092213
next epoch lr is 0.00040769130904675196, lr_dacay is 0.995


Epoch 179:
Total Loss: 0.1312166005373001
Running time: 45.3119535446167
learning rate is 0.00040769130904675196
next epoch lr is 0.0004056528525015182, lr_dacay is 0.995


Epoch 180:
Total Loss: 0.02500661090016365
Running time: 45.662524461746216
learning rate is 0.0004056528525015182
next epoch lr is 0.0004036245882390106, lr_dacay is 0.995


Epoch 181:
Total Loss: 0.01725262962281704
Running time: 45.4779417514801
learning rate is 0.0004036245882390106
next epoch lr is 0.00040160646529781557, lr_dacay is 0.995


Epoch 182:
Total Loss: 0.04364467039704323
Running time: 45.308855295181274
learning rate is 0.00040160646529781557
next epoch lr is 0.00039959843297132647, lr_dacay is 0.995


Epoch 183:
Total Loss: 0.029681703075766563
Running time: 45.76032209396362
learning rate is 0.00039959843297132647
next epoch lr is 0.00039760044080646985, lr_dacay is 0.995


Epoch 184:
Total Loss: 0.029111409559845924
Running time: 45.69007468223572
learning rate is 0.00039760044080646985
next epoch lr is 0.0003956124386024375, lr_dacay is 0.995


Epoch 185:
Total Loss: 0.037082452327013016
Running time: 45.59384536743164
learning rate is 0.0003956124386024375
next epoch lr is 0.0003936343764094253, lr_dacay is 0.995


Epoch 186:
Total Loss: 0.06135527044534683
Running time: 45.35862898826599
learning rate is 0.0003936343764094253
next epoch lr is 0.00039166620452737815, lr_dacay is 0.995


Epoch 187:
Total Loss: 0.022707540541887283
Running time: 45.607895374298096
learning rate is 0.00039166620452737815
next epoch lr is 0.00038970787350474124, lr_dacay is 0.995


Epoch 188:
Total Loss: 0.015448677353560925
Running time: 45.71621513366699
learning rate is 0.00038970787350474124
next epoch lr is 0.0003877593341372175, lr_dacay is 0.995


Epoch 189:
Total Loss: 0.02267291024327278
Running time: 45.64392685890198
learning rate is 0.0003877593341372175
next epoch lr is 0.00038582053746653145, lr_dacay is 0.995


Epoch 190:
Total Loss: 0.02976040169596672
Running time: 45.47301268577576
learning rate is 0.00038582053746653145
next epoch lr is 0.0003838914347791988, lr_dacay is 0.995


Epoch 191:
Total Loss: 0.04672762751579285
Running time: 45.38038182258606
learning rate is 0.0003838914347791988
next epoch lr is 0.0003819719776053028, lr_dacay is 0.995


Epoch 192:
Total Loss: 0.025122251361608505
Running time: 45.59431862831116
learning rate is 0.0003819719776053028
next epoch lr is 0.00038006211771727627, lr_dacay is 0.995


Epoch 193:
Total Loss: 0.03454899042844772
Running time: 45.85668992996216
learning rate is 0.00038006211771727627
next epoch lr is 0.0003781618071286899, lr_dacay is 0.995


Epoch 194:
Total Loss: 0.07024218887090683
Running time: 45.69946002960205
learning rate is 0.0003781618071286899
next epoch lr is 0.00037627099809304647, lr_dacay is 0.995


Epoch 195:
Total Loss: 0.02931000478565693
Running time: 45.52211022377014
learning rate is 0.00037627099809304647
next epoch lr is 0.00037438964310258126, lr_dacay is 0.995


Epoch 196:
Total Loss: 0.007184779271483421
Running time: 45.439260482788086
learning rate is 0.00037438964310258126
next epoch lr is 0.00037251769488706835, lr_dacay is 0.995


Epoch 197:
Total Loss: 0.011609231121838093
Running time: 45.313456296920776
learning rate is 0.00037251769488706835
next epoch lr is 0.000370655106412633, lr_dacay is 0.995


Epoch 198:
Total Loss: 0.014240507036447525
Running time: 45.6211793422699
learning rate is 0.000370655106412633
next epoch lr is 0.00036880183088056984, lr_dacay is 0.995


Epoch 199:
Total Loss: 0.04044857248663902
Running time: 45.52062201499939
learning rate is 0.00036880183088056984
next epoch lr is 0.000366957821726167, lr_dacay is 0.995


Epoch 200:
Total Loss: 0.029705112800002098
Running time: 45.290465116500854
learning rate is 0.000366957821726167
next epoch lr is 0.00036512303261753613, lr_dacay is 0.995


Epoch 201:
Total Loss: 0.015947813168168068
Running time: 45.483497619628906
learning rate is 0.00036512303261753613
next epoch lr is 0.00036329741745444845, lr_dacay is 0.995


Epoch 202:
Total Loss: 0.017484504729509354
Running time: 45.24909496307373
learning rate is 0.00036329741745444845
next epoch lr is 0.0003614809303671762, lr_dacay is 0.995


Epoch 203:
Total Loss: 0.050987210124731064
Running time: 45.659428358078
learning rate is 0.0003614809303671762
next epoch lr is 0.0003596735257153403, lr_dacay is 0.995


Epoch 204:
Total Loss: 0.03933711722493172
Running time: 45.72002840042114
learning rate is 0.0003596735257153403
next epoch lr is 0.00035787515808676363, lr_dacay is 0.995


Epoch 205:
Total Loss: 0.031769026070833206
Running time: 45.737818241119385
learning rate is 0.00035787515808676363
next epoch lr is 0.00035608578229632984, lr_dacay is 0.995


Epoch 206:
Total Loss: 0.02823670394718647
Running time: 45.31359624862671
learning rate is 0.00035608578229632984
next epoch lr is 0.0003543053533848482, lr_dacay is 0.995


Epoch 207:
Total Loss: 0.021993404254317284
Running time: 45.303183794021606
learning rate is 0.0003543053533848482
next epoch lr is 0.00035253382661792394, lr_dacay is 0.995


Epoch 208:
Total Loss: 0.016475103795528412
Running time: 45.58282470703125
learning rate is 0.00035253382661792394
next epoch lr is 0.0003507711574848343, lr_dacay is 0.995


Epoch 209:
Total Loss: 0.012722347863018513
Running time: 45.72052717208862
learning rate is 0.0003507711574848343
next epoch lr is 0.00034901730169741013, lr_dacay is 0.995


Epoch 210:
Total Loss: 0.02379699796438217
Running time: 45.434699296951294
learning rate is 0.00034901730169741013
next epoch lr is 0.0003472722151889231, lr_dacay is 0.995


Epoch 211:
Total Loss: 0.02329178899526596
Running time: 45.6492760181427
learning rate is 0.0003472722151889231
next epoch lr is 0.0003455358541129785, lr_dacay is 0.995


Epoch 212:
Total Loss: 0.033085115253925323
Running time: 45.56769609451294
learning rate is 0.0003455358541129785
next epoch lr is 0.0003438081748424136, lr_dacay is 0.995


Epoch 213:
Total Loss: 0.03151742368936539
Running time: 45.34256029129028
learning rate is 0.0003438081748424136
next epoch lr is 0.0003420891339682015, lr_dacay is 0.995


Epoch 214:
Total Loss: 0.02086048386991024
Running time: 45.497474193573
learning rate is 0.0003420891339682015
next epoch lr is 0.0003403786882983605, lr_dacay is 0.995


Epoch 215:
Total Loss: 0.025568174198269844
Running time: 45.707735776901245
learning rate is 0.0003403786882983605
next epoch lr is 0.0003386767948568687, lr_dacay is 0.995


Epoch 216:
Total Loss: 0.028367584571242332
Running time: 45.70633387565613
learning rate is 0.0003386767948568687
next epoch lr is 0.00033698341088258437, lr_dacay is 0.995


Epoch 217:
Total Loss: 0.007799457758665085
Running time: 45.58230996131897
learning rate is 0.00033698341088258437
next epoch lr is 0.00033529849382817143, lr_dacay is 0.995


Epoch 218:
Total Loss: 0.0075171045027673244
Running time: 45.79880166053772
learning rate is 0.00033529849382817143
next epoch lr is 0.00033362200135903056, lr_dacay is 0.995


Epoch 219:
Total Loss: 0.013495288789272308
Running time: 45.3763313293457
learning rate is 0.00033362200135903056
next epoch lr is 0.0003319538913522354, lr_dacay is 0.995


Epoch 220:
Total Loss: 0.022878292948007584
Running time: 45.279775619506836
learning rate is 0.0003319538913522354
next epoch lr is 0.00033029412189547426, lr_dacay is 0.995


Epoch 221:
Total Loss: 0.022622477263212204
Running time: 45.45521593093872
learning rate is 0.00033029412189547426
next epoch lr is 0.0003286426512859969, lr_dacay is 0.995


Epoch 222:
Total Loss: 0.013859180733561516
Running time: 45.566489458084106
learning rate is 0.0003286426512859969
next epoch lr is 0.0003269994380295669, lr_dacay is 0.995


Epoch 223:
Total Loss: 0.012445925734937191
Running time: 45.49882388114929
learning rate is 0.0003269994380295669
next epoch lr is 0.0003253644408394191, lr_dacay is 0.995


Epoch 224:
Total Loss: 0.03159502521157265
Running time: 45.48558497428894
learning rate is 0.0003253644408394191
next epoch lr is 0.000323737618635222, lr_dacay is 0.995


Epoch 225:
Total Loss: 0.019914710894227028
Running time: 45.82931637763977
learning rate is 0.000323737618635222
next epoch lr is 0.00032211893054204585, lr_dacay is 0.995


Epoch 226:
Total Loss: 0.014303539879620075
Running time: 45.478243350982666
learning rate is 0.00032211893054204585
next epoch lr is 0.0003205083358893356, lr_dacay is 0.995


Epoch 227:
Total Loss: 0.01243556383997202
Running time: 45.746954917907715
learning rate is 0.0003205083358893356
next epoch lr is 0.0003189057942098889, lr_dacay is 0.995


Epoch 228:
Total Loss: 0.008677095174789429
Running time: 45.324464559555054
learning rate is 0.0003189057942098889
next epoch lr is 0.00031731126523883944, lr_dacay is 0.995


Epoch 229:
Total Loss: 0.010001275688409805
Running time: 45.29986500740051
learning rate is 0.00031731126523883944
next epoch lr is 0.00031572470891264525, lr_dacay is 0.995


Epoch 230:
Total Loss: 0.015311816707253456
Running time: 45.478848457336426
learning rate is 0.00031572470891264525
next epoch lr is 0.000314146085368082, lr_dacay is 0.995


Epoch 231:
Total Loss: 0.020169345661997795
Running time: 45.32701063156128
learning rate is 0.000314146085368082
next epoch lr is 0.0003125753549412416, lr_dacay is 0.995


Epoch 232:
Total Loss: 0.012652305886149406
Running time: 45.51517868041992
learning rate is 0.0003125753549412416
next epoch lr is 0.0003110124781665354, lr_dacay is 0.995


Epoch 233:
Total Loss: 0.012509923428297043
Running time: 45.488643646240234
learning rate is 0.0003110124781665354
next epoch lr is 0.00030945741577570273, lr_dacay is 0.995


Epoch 234:
Total Loss: 0.01880481094121933
Running time: 45.550663471221924
learning rate is 0.00030945741577570273
next epoch lr is 0.0003079101286968242, lr_dacay is 0.995


Epoch 235:
Total Loss: 0.014066697098314762
Running time: 45.28240203857422
learning rate is 0.0003079101286968242
next epoch lr is 0.0003063705780533401, lr_dacay is 0.995


Epoch 236:
Total Loss: 0.022236686199903488
Running time: 45.478235721588135
learning rate is 0.0003063705780533401
next epoch lr is 0.0003048387251630734, lr_dacay is 0.995


Epoch 237:
Total Loss: 0.02033696509897709
Running time: 45.56036567687988
learning rate is 0.0003048387251630734
next epoch lr is 0.000303314531537258, lr_dacay is 0.995


Epoch 238:
Total Loss: 0.007699844893068075
Running time: 45.304115533828735
learning rate is 0.000303314531537258
next epoch lr is 0.0003017979588795717, lr_dacay is 0.995


Epoch 239:
Total Loss: 0.0045230514369904995
Running time: 45.54422855377197
learning rate is 0.0003017979588795717
next epoch lr is 0.0003002889690851738, lr_dacay is 0.995


Epoch 240:
Total Loss: 0.011366738937795162
Running time: 45.23238444328308
learning rate is 0.0003002889690851738
next epoch lr is 0.000298787524239748, lr_dacay is 0.995


Epoch 241:
Total Loss: 0.016263971105217934
Running time: 45.345266819000244
learning rate is 0.000298787524239748
next epoch lr is 0.0002972935866185492, lr_dacay is 0.995


Epoch 242:
Total Loss: 0.011345619335770607
Running time: 45.54472208023071
learning rate is 0.0002972935866185492
next epoch lr is 0.00029580711868545646, lr_dacay is 0.995


Epoch 243:
Total Loss: 0.011769239790737629
Running time: 45.52665710449219
learning rate is 0.00029580711868545646
next epoch lr is 0.0002943280830920292, lr_dacay is 0.995


Epoch 244:
Total Loss: 0.007073984015733004
Running time: 45.742326498031616
learning rate is 0.0002943280830920292
next epoch lr is 0.00029285644267656904, lr_dacay is 0.995


Epoch 245:
Total Loss: 0.007883844897150993
Running time: 45.40130925178528
learning rate is 0.00029285644267656904
next epoch lr is 0.0002913921604631862, lr_dacay is 0.995


Epoch 246:
Total Loss: 0.005148009862750769
Running time: 45.418869972229004
learning rate is 0.0002913921604631862
next epoch lr is 0.00028993519966087026, lr_dacay is 0.995


Epoch 247:
Total Loss: 0.012077314779162407
Running time: 45.749266147613525
learning rate is 0.00028993519966087026
next epoch lr is 0.0002884855236625659, lr_dacay is 0.995


Epoch 248:
Total Loss: 0.018165936693549156
Running time: 45.40869188308716
learning rate is 0.0002884855236625659
next epoch lr is 0.00028704309604425307, lr_dacay is 0.995


Epoch 249:
Total Loss: 0.013113206252455711
Running time: 45.62884593009949
learning rate is 0.00028704309604425307
next epoch lr is 0.0002856078805640318, lr_dacay is 0.995


Epoch 250:
Total Loss: 0.009696346707642078
Running time: 45.77289414405823
learning rate is 0.0002856078805640318
next epoch lr is 0.0002841798411612116, lr_dacay is 0.995


Epoch 251:
Total Loss: 0.007920660078525543
Running time: 45.47294020652771
learning rate is 0.0002841798411612116
next epoch lr is 0.0002827589419554055, lr_dacay is 0.995


Epoch 252:
Total Loss: 0.004486920312047005
Running time: 45.32726001739502
learning rate is 0.0002827589419554055
next epoch lr is 0.0002813451472456285, lr_dacay is 0.995


Epoch 253:
Total Loss: 0.02670234441757202
Running time: 45.472188234329224
learning rate is 0.0002813451472456285
next epoch lr is 0.0002799384215094004, lr_dacay is 0.995


Epoch 254:
Total Loss: 0.012771185487508774
Running time: 45.29834461212158
learning rate is 0.0002799384215094004
next epoch lr is 0.00027853872940185336, lr_dacay is 0.995


Epoch 255:
Total Loss: 0.005867447704076767
Running time: 45.60922074317932
learning rate is 0.00027853872940185336
next epoch lr is 0.0002771460357548441, lr_dacay is 0.995


Epoch 256:
Total Loss: 0.006227931473404169
Running time: 45.71293544769287
learning rate is 0.0002771460357548441
next epoch lr is 0.0002757603055760699, lr_dacay is 0.995


Epoch 257:
Total Loss: 0.005489458795636892
Running time: 45.42680025100708
learning rate is 0.0002757603055760699
next epoch lr is 0.0002743815040481895, lr_dacay is 0.995


Epoch 258:
Total Loss: 0.02545374259352684
Running time: 45.3232216835022
learning rate is 0.0002743815040481895
next epoch lr is 0.00027300959652794857, lr_dacay is 0.995


Epoch 259:
Total Loss: 0.013129410333931446
Running time: 45.42548322677612
learning rate is 0.00027300959652794857
next epoch lr is 0.0002716445485453088, lr_dacay is 0.995


Epoch 260:
Total Loss: 0.026056895032525063
Running time: 45.28528714179993
learning rate is 0.0002716445485453088
next epoch lr is 0.0002702863258025823, lr_dacay is 0.995


Epoch 261:
Total Loss: 0.01506081037223339
Running time: 45.61890935897827
learning rate is 0.0002702863258025823
next epoch lr is 0.00026893489417356936, lr_dacay is 0.995


Epoch 262:
Total Loss: 0.0034932559356093407
Running time: 45.41212844848633
learning rate is 0.00026893489417356936
next epoch lr is 0.0002675902197027015, lr_dacay is 0.995


Epoch 263:
Total Loss: 0.006711592432111502
Running time: 45.672508001327515
learning rate is 0.0002675902197027015
next epoch lr is 0.000266252268604188, lr_dacay is 0.995


Epoch 264:
Total Loss: 0.0035061982925981283
Running time: 45.56593346595764
learning rate is 0.000266252268604188
next epoch lr is 0.0002649210072611671, lr_dacay is 0.995


Epoch 265:
Total Loss: 0.00433262437582016
Running time: 45.60688519477844
learning rate is 0.0002649210072611671
next epoch lr is 0.0002635964022248612, lr_dacay is 0.995


Epoch 266:
Total Loss: 0.005469253286719322
Running time: 45.3830292224884
learning rate is 0.0002635964022248612
next epoch lr is 0.0002622784202137369, lr_dacay is 0.995


Epoch 267:
Total Loss: 0.008839676156640053
Running time: 45.37188506126404
learning rate is 0.0002622784202137369
next epoch lr is 0.00026096702811266825, lr_dacay is 0.995


Epoch 268:
Total Loss: 0.008520704694092274
Running time: 45.302539348602295
learning rate is 0.00026096702811266825
next epoch lr is 0.0002596621929721049, lr_dacay is 0.995


Epoch 269:
Total Loss: 0.029139595106244087
Running time: 45.38090372085571
learning rate is 0.0002596621929721049
next epoch lr is 0.0002583638820072444, lr_dacay is 0.995


Epoch 270:
Total Loss: 0.011088506318628788
Running time: 45.47189521789551
learning rate is 0.0002583638820072444
next epoch lr is 0.00025707206259720813, lr_dacay is 0.995


Epoch 271:
Total Loss: 0.0024366462603211403
Running time: 45.36414933204651
learning rate is 0.00025707206259720813
next epoch lr is 0.0002557867022842221, lr_dacay is 0.995


Epoch 272:
Total Loss: 0.0015506811905652285
Running time: 45.34436869621277
learning rate is 0.0002557867022842221
next epoch lr is 0.00025450776877280096, lr_dacay is 0.995


Epoch 273:
Total Loss: 0.0007884278311394155
Running time: 45.6725172996521
learning rate is 0.00025450776877280096
next epoch lr is 0.00025323522992893693, lr_dacay is 0.995


Epoch 274:
Total Loss: 0.0003497122961562127
Running time: 45.32919955253601
learning rate is 0.00025323522992893693
next epoch lr is 0.00025196905377929227, lr_dacay is 0.995


Epoch 275:
Total Loss: 0.003655289765447378
Running time: 45.451974630355835
learning rate is 0.00025196905377929227
next epoch lr is 0.0002507092085103958, lr_dacay is 0.995


Epoch 276:
Total Loss: 0.007924607954919338
Running time: 45.500025510787964
learning rate is 0.0002507092085103958
next epoch lr is 0.0002494556624678438, lr_dacay is 0.995


Epoch 277:
Total Loss: 0.0046308948658406734
Running time: 45.33301782608032
learning rate is 0.0002494556624678438
next epoch lr is 0.0002482083841555046, lr_dacay is 0.995


Epoch 278:
Total Loss: 0.03057132661342621
Running time: 45.855058908462524
learning rate is 0.0002482083841555046
next epoch lr is 0.00024696734223472706, lr_dacay is 0.995


Epoch 279:
Total Loss: 0.0242910273373127
Running time: 45.717825412750244
learning rate is 0.00024696734223472706
next epoch lr is 0.00024573250552355344, lr_dacay is 0.995


Epoch 280:
Total Loss: 0.013599696569144726
Running time: 45.714730978012085
learning rate is 0.00024573250552355344
next epoch lr is 0.00024450384299593567, lr_dacay is 0.995


Epoch 281:
Total Loss: 0.009039163589477539
Running time: 45.42065358161926
learning rate is 0.00024450384299593567
next epoch lr is 0.000243281323780956, lr_dacay is 0.995


Epoch 282:
Total Loss: 0.004414767492562532
Running time: 45.212483406066895
learning rate is 0.000243281323780956
next epoch lr is 0.0002420649171620512, lr_dacay is 0.995


Epoch 283:
Total Loss: 0.0026498264633119106
Running time: 45.59094500541687
learning rate is 0.0002420649171620512
next epoch lr is 0.00024085459257624093, lr_dacay is 0.995


Epoch 284:
Total Loss: 0.006469727959483862
Running time: 45.62502360343933
learning rate is 0.00024085459257624093
next epoch lr is 0.00023965031961335973, lr_dacay is 0.995


Epoch 285:
Total Loss: 0.0037122636567801237
Running time: 45.423222064971924
learning rate is 0.00023965031961335973
next epoch lr is 0.00023845206801529294, lr_dacay is 0.995


Epoch 286:
Total Loss: 0.01077917218208313
Running time: 45.67440581321716
learning rate is 0.00023845206801529294
next epoch lr is 0.00023725980767521648, lr_dacay is 0.995


Epoch 287:
Total Loss: 0.008679520338773727
Running time: 45.28723907470703
learning rate is 0.00023725980767521648
next epoch lr is 0.00023607350863684038, lr_dacay is 0.995


Epoch 288:
Total Loss: 0.012843158096075058
Running time: 45.546714782714844
learning rate is 0.00023607350863684038
next epoch lr is 0.00023489314109365617, lr_dacay is 0.995


Epoch 289:
Total Loss: 0.003671889426186681
Running time: 45.42427468299866
learning rate is 0.00023489314109365617
next epoch lr is 0.0002337186753881879, lr_dacay is 0.995


Epoch 290:
Total Loss: 0.0026337679009884596
Running time: 45.73317074775696
learning rate is 0.0002337186753881879
next epoch lr is 0.00023255008201124696, lr_dacay is 0.995


Epoch 291:
Total Loss: 0.0033439279068261385
Running time: 45.43058776855469
learning rate is 0.00023255008201124696
next epoch lr is 0.00023138733160119073, lr_dacay is 0.995


Epoch 292:
Total Loss: 0.003071428509429097
Running time: 45.37325859069824
learning rate is 0.00023138733160119073
next epoch lr is 0.0002302303949431848, lr_dacay is 0.995


Epoch 293:
Total Loss: 0.0032682905439287424
Running time: 45.57539701461792
learning rate is 0.0002302303949431848
next epoch lr is 0.00022907924296846886, lr_dacay is 0.995


Epoch 294:
Total Loss: 0.0024352925829589367
Running time: 45.59100365638733
learning rate is 0.00022907924296846886
next epoch lr is 0.0002279338467536265, lr_dacay is 0.995


Epoch 295:
Total Loss: 0.003648504614830017
Running time: 45.5738844871521
learning rate is 0.0002279338467536265
next epoch lr is 0.00022679417751985838, lr_dacay is 0.995


Epoch 296:
Total Loss: 0.005420044995844364
Running time: 45.3920841217041
learning rate is 0.00022679417751985838
next epoch lr is 0.00022566020663225908, lr_dacay is 0.995


Epoch 297:
Total Loss: 0.0070439232513308525
Running time: 45.57110142707825
learning rate is 0.00022566020663225908
next epoch lr is 0.00022453190559909778, lr_dacay is 0.995


Epoch 298:
Total Loss: 0.003472470911219716
Running time: 45.44574451446533
learning rate is 0.00022453190559909778
next epoch lr is 0.00022340924607110228, lr_dacay is 0.995


Epoch 299:
Total Loss: 0.002478026319295168
Running time: 45.69632124900818
learning rate is 0.00022340924607110228
next epoch lr is 0.00022229219984074678, lr_dacay is 0.995


