Epoch 0:
Total Loss: 19872.958984375
Running time: 11.317400217056274
learning rate is 0.001
next epoch lr is 0.000995, lr_dacay is 0.995


Epoch 1:
Total Loss: 16645.908203125
Running time: 11.287086725234985
learning rate is 0.000995
next epoch lr is 0.000990025, lr_dacay is 0.995


Epoch 2:
Total Loss: 16553.78515625
Running time: 11.836050987243652
learning rate is 0.000990025
next epoch lr is 0.000985074875, lr_dacay is 0.995


Epoch 3:
Total Loss: 16476.859375
Running time: 11.47835659980774
learning rate is 0.000985074875
next epoch lr is 0.000980149500625, lr_dacay is 0.995


Epoch 4:
Total Loss: 16475.314453125
Running time: 11.386278629302979
learning rate is 0.000980149500625
next epoch lr is 0.000975248753121875, lr_dacay is 0.995


Epoch 5:
Total Loss: 16477.650390625
Running time: 11.43651270866394
learning rate is 0.000975248753121875
next epoch lr is 0.0009703725093562657, lr_dacay is 0.995


Epoch 6:
Total Loss: 16485.94921875
Running time: 11.309926271438599
learning rate is 0.0009703725093562657
next epoch lr is 0.0009655206468094843, lr_dacay is 0.995


Epoch 7:
Total Loss: 16464.509765625
Running time: 11.206159353256226
learning rate is 0.0009655206468094843
next epoch lr is 0.0009606930435754369, lr_dacay is 0.995


Epoch 8:
Total Loss: 16440.244140625
Running time: 11.233801364898682
learning rate is 0.0009606930435754369
next epoch lr is 0.0009558895783575597, lr_dacay is 0.995


Epoch 9:
Total Loss: 16446.2578125
Running time: 11.098865509033203
learning rate is 0.0009558895783575597
next epoch lr is 0.0009511101304657719, lr_dacay is 0.995


Epoch 10:
Total Loss: 16425.22265625
Running time: 11.275184869766235
learning rate is 0.0009511101304657719
next epoch lr is 0.000946354579813443, lr_dacay is 0.995


Epoch 11:
Total Loss: 16378.9521484375
Running time: 11.130659341812134
learning rate is 0.000946354579813443
next epoch lr is 0.0009416228069143757, lr_dacay is 0.995


Epoch 12:
Total Loss: 16372.646484375
Running time: 11.229174375534058
learning rate is 0.0009416228069143757
next epoch lr is 0.0009369146928798038, lr_dacay is 0.995


Epoch 13:
Total Loss: 16365.509765625
Running time: 11.386503458023071
learning rate is 0.0009369146928798038
next epoch lr is 0.0009322301194154048, lr_dacay is 0.995


Epoch 14:
Total Loss: 16349.9296875
Running time: 11.31631851196289
learning rate is 0.0009322301194154048
next epoch lr is 0.0009275689688183278, lr_dacay is 0.995


Epoch 15:
Total Loss: 16351.900390625
Running time: 11.254579782485962
learning rate is 0.0009275689688183278
next epoch lr is 0.0009229311239742361, lr_dacay is 0.995


Epoch 16:
Total Loss: 16273.6337890625
Running time: 11.42042064666748
learning rate is 0.0009229311239742361
next epoch lr is 0.0009183164683543649, lr_dacay is 0.995


Epoch 17:
Total Loss: 16258.05078125
Running time: 11.662443161010742
learning rate is 0.0009183164683543649
next epoch lr is 0.0009137248860125931, lr_dacay is 0.995


Epoch 18:
Total Loss: 16285.4638671875
Running time: 11.817199945449829
learning rate is 0.0009137248860125931
next epoch lr is 0.0009091562615825302, lr_dacay is 0.995


Epoch 19:
Total Loss: 16262.2294921875
Running time: 11.411607503890991
learning rate is 0.0009091562615825302
next epoch lr is 0.0009046104802746175, lr_dacay is 0.995


Epoch 20:
Total Loss: 16259.1455078125
Running time: 11.484725713729858
learning rate is 0.0009046104802746175
next epoch lr is 0.0009000874278732445, lr_dacay is 0.995


Epoch 21:
Total Loss: 16219.517578125
Running time: 11.229976177215576
learning rate is 0.0009000874278732445
next epoch lr is 0.0008955869907338783, lr_dacay is 0.995


Epoch 22:
Total Loss: 16211.693359375
Running time: 11.851098775863647
learning rate is 0.0008955869907338783
next epoch lr is 0.0008911090557802089, lr_dacay is 0.995


Epoch 23:
Total Loss: 16190.365234375
Running time: 11.319046974182129
learning rate is 0.0008911090557802089
next epoch lr is 0.0008866535105013078, lr_dacay is 0.995


Epoch 24:
Total Loss: 16169.1953125
Running time: 11.230332851409912
learning rate is 0.0008866535105013078
next epoch lr is 0.0008822202429488013, lr_dacay is 0.995


Epoch 25:
Total Loss: 16128.5986328125
Running time: 11.300343751907349
learning rate is 0.0008822202429488013
next epoch lr is 0.0008778091417340573, lr_dacay is 0.995


Epoch 26:
Total Loss: 16130.9658203125
Running time: 11.084546566009521
learning rate is 0.0008778091417340573
next epoch lr is 0.000873420096025387, lr_dacay is 0.995


Epoch 27:
Total Loss: 16075.0771484375
Running time: 11.61893105506897
learning rate is 0.000873420096025387
next epoch lr is 0.0008690529955452601, lr_dacay is 0.995


Epoch 28:
Total Loss: 16012.7666015625
Running time: 11.343725442886353
learning rate is 0.0008690529955452601
next epoch lr is 0.0008647077305675338, lr_dacay is 0.995


Epoch 29:
Total Loss: 15962.404296875
Running time: 11.18184208869934
learning rate is 0.0008647077305675338
next epoch lr is 0.0008603841919146961, lr_dacay is 0.995


Epoch 30:
Total Loss: 15931.236328125
Running time: 11.996803522109985
learning rate is 0.0008603841919146961
next epoch lr is 0.0008560822709551226, lr_dacay is 0.995


Epoch 31:
Total Loss: 15904.28125
Running time: 11.628181219100952
learning rate is 0.0008560822709551226
next epoch lr is 0.000851801859600347, lr_dacay is 0.995


Epoch 32:
Total Loss: 15822.015625
Running time: 11.489774227142334
learning rate is 0.000851801859600347
next epoch lr is 0.0008475428503023452, lr_dacay is 0.995


Epoch 33:
Total Loss: 15813.005859375
Running time: 11.288607835769653
learning rate is 0.0008475428503023452
next epoch lr is 0.0008433051360508335, lr_dacay is 0.995


Epoch 34:
Total Loss: 15787.1416015625
Running time: 11.47714638710022
learning rate is 0.0008433051360508335
next epoch lr is 0.0008390886103705794, lr_dacay is 0.995


Epoch 35:
Total Loss: 15781.267578125
Running time: 11.858770847320557
learning rate is 0.0008390886103705794
next epoch lr is 0.0008348931673187264, lr_dacay is 0.995


Epoch 36:
Total Loss: 15711.1318359375
Running time: 11.0648832321167
learning rate is 0.0008348931673187264
next epoch lr is 0.0008307187014821328, lr_dacay is 0.995


Epoch 37:
Total Loss: 15687.3720703125
Running time: 11.642359018325806
learning rate is 0.0008307187014821328
next epoch lr is 0.0008265651079747222, lr_dacay is 0.995


Epoch 38:
Total Loss: 15660.8056640625
Running time: 11.382694005966187
learning rate is 0.0008265651079747222
next epoch lr is 0.0008224322824348485, lr_dacay is 0.995


Epoch 39:
Total Loss: 15649.984375
Running time: 11.273307800292969
learning rate is 0.0008224322824348485
next epoch lr is 0.0008183201210226743, lr_dacay is 0.995


Epoch 40:
Total Loss: 15596.7412109375
Running time: 11.230797529220581
learning rate is 0.0008183201210226743
next epoch lr is 0.0008142285204175609, lr_dacay is 0.995


Epoch 41:
Total Loss: 15604.9609375
Running time: 11.252557754516602
learning rate is 0.0008142285204175609
next epoch lr is 0.0008101573778154731, lr_dacay is 0.995


Epoch 42:
Total Loss: 15578.6884765625
Running time: 11.880484580993652
learning rate is 0.0008101573778154731
next epoch lr is 0.0008061065909263957, lr_dacay is 0.995


Epoch 43:
Total Loss: 15575.294921875
Running time: 11.480615377426147
learning rate is 0.0008061065909263957
next epoch lr is 0.0008020760579717638, lr_dacay is 0.995


Epoch 44:
Total Loss: 15540.427734375
Running time: 11.720586061477661
learning rate is 0.0008020760579717638
next epoch lr is 0.000798065677681905, lr_dacay is 0.995


Epoch 45:
Total Loss: 15537.140625
Running time: 11.194473028182983
learning rate is 0.000798065677681905
next epoch lr is 0.0007940753492934955, lr_dacay is 0.995


Epoch 46:
Total Loss: 15501.263671875
Running time: 11.283454895019531
learning rate is 0.0007940753492934955
next epoch lr is 0.000790104972547028, lr_dacay is 0.995


Epoch 47:
Total Loss: 15491.51171875
Running time: 11.287114143371582
learning rate is 0.000790104972547028
next epoch lr is 0.0007861544476842928, lr_dacay is 0.995


Epoch 48:
Total Loss: 15485.0576171875
Running time: 11.039666175842285
learning rate is 0.0007861544476842928
next epoch lr is 0.0007822236754458713, lr_dacay is 0.995


Epoch 49:
Total Loss: 15441.7255859375
Running time: 11.277861595153809
learning rate is 0.0007822236754458713
next epoch lr is 0.0007783125570686419, lr_dacay is 0.995


Epoch 50:
Total Loss: 15498.8369140625
Running time: 11.517203569412231
learning rate is 0.0007783125570686419
next epoch lr is 0.0007744209942832988, lr_dacay is 0.995


Epoch 51:
Total Loss: 15428.484375
Running time: 11.204064846038818
learning rate is 0.0007744209942832988
next epoch lr is 0.0007705488893118823, lr_dacay is 0.995


Epoch 52:
Total Loss: 15438.767578125
Running time: 11.066165208816528
learning rate is 0.0007705488893118823
next epoch lr is 0.0007666961448653228, lr_dacay is 0.995


Epoch 53:
Total Loss: 15394.3896484375
Running time: 10.997299909591675
learning rate is 0.0007666961448653228
next epoch lr is 0.0007628626641409962, lr_dacay is 0.995


Epoch 54:
Total Loss: 15371.1298828125
Running time: 11.068911075592041
learning rate is 0.0007628626641409962
next epoch lr is 0.0007590483508202912, lr_dacay is 0.995


Epoch 55:
Total Loss: 15394.681640625
Running time: 10.946789503097534
learning rate is 0.0007590483508202912
next epoch lr is 0.0007552531090661898, lr_dacay is 0.995


Epoch 56:
Total Loss: 15370.7958984375
Running time: 11.534318685531616
learning rate is 0.0007552531090661898
next epoch lr is 0.0007514768435208588, lr_dacay is 0.995


Epoch 57:
Total Loss: 15356.6318359375
Running time: 11.786053657531738
learning rate is 0.0007514768435208588
next epoch lr is 0.0007477194593032545, lr_dacay is 0.995


Epoch 58:
Total Loss: 15347.23046875
Running time: 11.226253271102905
learning rate is 0.0007477194593032545
next epoch lr is 0.0007439808620067382, lr_dacay is 0.995


Epoch 59:
Total Loss: 15294.4375
Running time: 11.39243459701538
learning rate is 0.0007439808620067382
next epoch lr is 0.0007402609576967046, lr_dacay is 0.995


Epoch 60:
Total Loss: 15310.541015625
Running time: 11.670188665390015
learning rate is 0.0007402609576967046
next epoch lr is 0.000736559652908221, lr_dacay is 0.995


Epoch 61:
Total Loss: 15328.1689453125
Running time: 11.188730001449585
learning rate is 0.000736559652908221
next epoch lr is 0.0007328768546436799, lr_dacay is 0.995


Epoch 62:
Total Loss: 15310.0966796875
Running time: 10.969250917434692
learning rate is 0.0007328768546436799
next epoch lr is 0.0007292124703704615, lr_dacay is 0.995


Epoch 63:
Total Loss: 15288.837890625
Running time: 11.543982982635498
learning rate is 0.0007292124703704615
next epoch lr is 0.0007255664080186091, lr_dacay is 0.995


Epoch 64:
Total Loss: 15280.4931640625
Running time: 11.786271333694458
learning rate is 0.0007255664080186091
next epoch lr is 0.0007219385759785161, lr_dacay is 0.995


Epoch 65:
Total Loss: 15279.3388671875
Running time: 11.346803903579712
learning rate is 0.0007219385759785161
next epoch lr is 0.0007183288830986235, lr_dacay is 0.995


Epoch 66:
Total Loss: 15269.6611328125
Running time: 11.427393198013306
learning rate is 0.0007183288830986235
next epoch lr is 0.0007147372386831303, lr_dacay is 0.995


Epoch 67:
Total Loss: 15285.3662109375
Running time: 11.245258569717407
learning rate is 0.0007147372386831303
next epoch lr is 0.0007111635524897147, lr_dacay is 0.995


Epoch 68:
Total Loss: 15233.5439453125
Running time: 11.07332706451416
learning rate is 0.0007111635524897147
next epoch lr is 0.0007076077347272661, lr_dacay is 0.995


Epoch 69:
Total Loss: 15235.173828125
Running time: 11.529803037643433
learning rate is 0.0007076077347272661
next epoch lr is 0.0007040696960536298, lr_dacay is 0.995


Epoch 70:
Total Loss: 15216.7333984375
Running time: 11.665741682052612
learning rate is 0.0007040696960536298
next epoch lr is 0.0007005493475733617, lr_dacay is 0.995


Epoch 71:
Total Loss: 15195.1650390625
Running time: 11.464068412780762
learning rate is 0.0007005493475733617
next epoch lr is 0.0006970466008354948, lr_dacay is 0.995


Epoch 72:
Total Loss: 15170.7109375
Running time: 12.81895399093628
learning rate is 0.0006970466008354948
next epoch lr is 0.0006935613678313174, lr_dacay is 0.995


Epoch 73:
Total Loss: 15162.27734375
Running time: 11.662236213684082
learning rate is 0.0006935613678313174
next epoch lr is 0.0006900935609921607, lr_dacay is 0.995


Epoch 74:
Total Loss: 15171.056640625
Running time: 11.882461071014404
learning rate is 0.0006900935609921607
next epoch lr is 0.0006866430931872, lr_dacay is 0.995


Epoch 75:
Total Loss: 15149.6533203125
Running time: 11.549367904663086
learning rate is 0.0006866430931872
next epoch lr is 0.000683209877721264, lr_dacay is 0.995


Epoch 76:
Total Loss: 15162.2177734375
Running time: 11.514588832855225
learning rate is 0.000683209877721264
next epoch lr is 0.0006797938283326577, lr_dacay is 0.995


Epoch 77:
Total Loss: 15138.078125
Running time: 11.219812154769897
learning rate is 0.0006797938283326577
next epoch lr is 0.0006763948591909945, lr_dacay is 0.995


Epoch 78:
Total Loss: 15115.3291015625
Running time: 11.298317432403564
learning rate is 0.0006763948591909945
next epoch lr is 0.0006730128848950395, lr_dacay is 0.995


Epoch 79:
Total Loss: 15146.064453125
Running time: 11.243268728256226
learning rate is 0.0006730128848950395
next epoch lr is 0.0006696478204705643, lr_dacay is 0.995


Epoch 80:
Total Loss: 15143.8642578125
Running time: 11.787039756774902
learning rate is 0.0006696478204705643
next epoch lr is 0.0006662995813682115, lr_dacay is 0.995


Epoch 81:
Total Loss: 15080.427734375
Running time: 11.077868461608887
learning rate is 0.0006662995813682115
next epoch lr is 0.0006629680834613704, lr_dacay is 0.995


Epoch 82:
Total Loss: 15109.2431640625
Running time: 11.503858089447021
learning rate is 0.0006629680834613704
next epoch lr is 0.0006596532430440636, lr_dacay is 0.995


Epoch 83:
Total Loss: 15078.58203125
Running time: 11.204113245010376
learning rate is 0.0006596532430440636
next epoch lr is 0.0006563549768288432, lr_dacay is 0.995


Epoch 84:
Total Loss: 15089.3837890625
Running time: 11.122533082962036
learning rate is 0.0006563549768288432
next epoch lr is 0.000653073201944699, lr_dacay is 0.995


Epoch 85:
Total Loss: 15069.826171875
Running time: 11.354312896728516
learning rate is 0.000653073201944699
next epoch lr is 0.0006498078359349755, lr_dacay is 0.995


Epoch 86:
Total Loss: 15034.216796875
Running time: 11.242798566818237
learning rate is 0.0006498078359349755
next epoch lr is 0.0006465587967553006, lr_dacay is 0.995


Epoch 87:
Total Loss: 15064.41796875
Running time: 11.293876647949219
learning rate is 0.0006465587967553006
next epoch lr is 0.0006433260027715241, lr_dacay is 0.995


Epoch 88:
Total Loss: 15052.658203125
Running time: 11.411768674850464
learning rate is 0.0006433260027715241
next epoch lr is 0.0006401093727576665, lr_dacay is 0.995


Epoch 89:
Total Loss: 15027.6064453125
Running time: 12.27792739868164
learning rate is 0.0006401093727576665
next epoch lr is 0.0006369088258938781, lr_dacay is 0.995


Epoch 90:
Total Loss: 15006.6015625
Running time: 11.762381553649902
learning rate is 0.0006369088258938781
next epoch lr is 0.0006337242817644087, lr_dacay is 0.995


Epoch 91:
Total Loss: 15018.404296875
Running time: 11.382044076919556
learning rate is 0.0006337242817644087
next epoch lr is 0.0006305556603555866, lr_dacay is 0.995


Epoch 92:
Total Loss: 15017.0341796875
Running time: 11.445611953735352
learning rate is 0.0006305556603555866
next epoch lr is 0.0006274028820538087, lr_dacay is 0.995


Epoch 93:
Total Loss: 14992.9814453125
Running time: 11.180805921554565
learning rate is 0.0006274028820538087
next epoch lr is 0.0006242658676435396, lr_dacay is 0.995


Epoch 94:
Total Loss: 14979.75
Running time: 11.39706802368164
learning rate is 0.0006242658676435396
next epoch lr is 0.0006211445383053219, lr_dacay is 0.995


Epoch 95:
Total Loss: 14973.8720703125
Running time: 11.110911846160889
learning rate is 0.0006211445383053219
next epoch lr is 0.0006180388156137953, lr_dacay is 0.995


Epoch 96:
Total Loss: 14986.0107421875
Running time: 11.274877309799194
learning rate is 0.0006180388156137953
next epoch lr is 0.0006149486215357262, lr_dacay is 0.995


Epoch 97:
Total Loss: 14950.2421875
Running time: 11.48547101020813
learning rate is 0.0006149486215357262
next epoch lr is 0.0006118738784280476, lr_dacay is 0.995


Epoch 98:
Total Loss: 14950.2978515625
Running time: 11.25731873512268
learning rate is 0.0006118738784280476
next epoch lr is 0.0006088145090359073, lr_dacay is 0.995


Epoch 99:
Total Loss: 14968.75390625
Running time: 11.44404935836792
learning rate is 0.0006088145090359073
next epoch lr is 0.0006057704364907278, lr_dacay is 0.995


Epoch 100:
Total Loss: 14909.708984375
Running time: 11.096024990081787
learning rate is 0.0006057704364907278
next epoch lr is 0.0006027415843082742, lr_dacay is 0.995


Epoch 101:
Total Loss: 14919.646484375
Running time: 11.266976118087769
learning rate is 0.0006027415843082742
next epoch lr is 0.0005997278763867329, lr_dacay is 0.995


Epoch 102:
Total Loss: 14916.79296875
Running time: 11.675545692443848
learning rate is 0.0005997278763867329
next epoch lr is 0.0005967292370047993, lr_dacay is 0.995


Epoch 103:
Total Loss: 14916.26953125
Running time: 11.487114429473877
learning rate is 0.0005967292370047993
next epoch lr is 0.0005937455908197753, lr_dacay is 0.995


Epoch 104:
Total Loss: 14903.6904296875
Running time: 11.172145366668701
learning rate is 0.0005937455908197753
next epoch lr is 0.0005907768628656764, lr_dacay is 0.995


Epoch 105:
Total Loss: 14903.07421875
Running time: 11.581939458847046
learning rate is 0.0005907768628656764
next epoch lr is 0.000587822978551348, lr_dacay is 0.995


Epoch 106:
Total Loss: 14894.041015625
Running time: 11.304152965545654
learning rate is 0.000587822978551348
next epoch lr is 0.0005848838636585913, lr_dacay is 0.995


Epoch 107:
Total Loss: 14883.1650390625
Running time: 11.419038534164429
learning rate is 0.0005848838636585913
next epoch lr is 0.0005819594443402983, lr_dacay is 0.995


Epoch 108:
Total Loss: 14896.6572265625
Running time: 11.198702096939087
learning rate is 0.0005819594443402983
next epoch lr is 0.0005790496471185969, lr_dacay is 0.995


Epoch 109:
Total Loss: 14863.9541015625
Running time: 11.393925666809082
learning rate is 0.0005790496471185969
next epoch lr is 0.0005761543988830039, lr_dacay is 0.995


Epoch 110:
Total Loss: 14861.255859375
Running time: 11.85963487625122
learning rate is 0.0005761543988830039
next epoch lr is 0.0005732736268885889, lr_dacay is 0.995


Epoch 111:
Total Loss: 14868.4091796875
Running time: 11.77750015258789
learning rate is 0.0005732736268885889
next epoch lr is 0.0005704072587541459, lr_dacay is 0.995


Epoch 112:
Total Loss: 14859.08984375
Running time: 11.031084299087524
learning rate is 0.0005704072587541459
next epoch lr is 0.0005675552224603752, lr_dacay is 0.995


Epoch 113:
Total Loss: 14842.8212890625
Running time: 11.189873456954956
learning rate is 0.0005675552224603752
next epoch lr is 0.0005647174463480733, lr_dacay is 0.995


Epoch 114:
Total Loss: 14834.2734375
Running time: 11.163537502288818
learning rate is 0.0005647174463480733
next epoch lr is 0.0005618938591163329, lr_dacay is 0.995


Epoch 115:
Total Loss: 14843.12109375
Running time: 11.315399885177612
learning rate is 0.0005618938591163329
next epoch lr is 0.0005590843898207513, lr_dacay is 0.995


Epoch 116:
Total Loss: 14822.958984375
Running time: 11.115016460418701
learning rate is 0.0005590843898207513
next epoch lr is 0.0005562889678716475, lr_dacay is 0.995


Epoch 117:
Total Loss: 14793.380859375
Running time: 10.957279920578003
learning rate is 0.0005562889678716475
next epoch lr is 0.0005535075230322892, lr_dacay is 0.995


Epoch 118:
Total Loss: 14788.236328125
Running time: 11.200146436691284
learning rate is 0.0005535075230322892
next epoch lr is 0.0005507399854171277, lr_dacay is 0.995


Epoch 119:
Total Loss: 14803.30859375
Running time: 11.404452800750732
learning rate is 0.0005507399854171277
next epoch lr is 0.0005479862854900421, lr_dacay is 0.995


Epoch 120:
Total Loss: 14813.3251953125
Running time: 11.17638635635376
learning rate is 0.0005479862854900421
next epoch lr is 0.0005452463540625918, lr_dacay is 0.995


Epoch 121:
Total Loss: 14773.2138671875
Running time: 11.229740619659424
learning rate is 0.0005452463540625918
next epoch lr is 0.0005425201222922788, lr_dacay is 0.995


Epoch 122:
Total Loss: 14815.662109375
Running time: 11.203457593917847
learning rate is 0.0005425201222922788
next epoch lr is 0.0005398075216808175, lr_dacay is 0.995


Epoch 123:
Total Loss: 14780.66015625
Running time: 11.347783327102661
learning rate is 0.0005398075216808175
next epoch lr is 0.0005371084840724133, lr_dacay is 0.995


Epoch 124:
Total Loss: 14786.2919921875
Running time: 11.656851053237915
learning rate is 0.0005371084840724133
next epoch lr is 0.0005344229416520513, lr_dacay is 0.995


Epoch 125:
Total Loss: 14801.3349609375
Running time: 11.44264030456543
learning rate is 0.0005344229416520513
next epoch lr is 0.000531750826943791, lr_dacay is 0.995


Epoch 126:
Total Loss: 14763.474609375
Running time: 11.559394598007202
learning rate is 0.000531750826943791
next epoch lr is 0.000529092072809072, lr_dacay is 0.995


Epoch 127:
Total Loss: 14766.6767578125
Running time: 11.373022317886353
learning rate is 0.000529092072809072
next epoch lr is 0.0005264466124450266, lr_dacay is 0.995


Epoch 128:
Total Loss: 14711.6904296875
Running time: 11.048216342926025
learning rate is 0.0005264466124450266
next epoch lr is 0.0005238143793828015, lr_dacay is 0.995


Epoch 129:
Total Loss: 14722.5986328125
Running time: 11.121524095535278
learning rate is 0.0005238143793828015
next epoch lr is 0.0005211953074858875, lr_dacay is 0.995


Epoch 130:
Total Loss: 14744.1064453125
Running time: 11.166452646255493
learning rate is 0.0005211953074858875
next epoch lr is 0.0005185893309484581, lr_dacay is 0.995


Epoch 131:
Total Loss: 14738.962890625
Running time: 11.345661401748657
learning rate is 0.0005185893309484581
next epoch lr is 0.0005159963842937158, lr_dacay is 0.995


Epoch 132:
Total Loss: 14734.2236328125
Running time: 11.083734512329102
learning rate is 0.0005159963842937158
next epoch lr is 0.0005134164023722472, lr_dacay is 0.995


Epoch 133:
Total Loss: 14725.7275390625
Running time: 11.305793523788452
learning rate is 0.0005134164023722472
next epoch lr is 0.000510849320360386, lr_dacay is 0.995


Epoch 134:
Total Loss: 14708.3974609375
Running time: 11.067771911621094
learning rate is 0.000510849320360386
next epoch lr is 0.0005082950737585841, lr_dacay is 0.995


Epoch 135:
Total Loss: 14721.7197265625
Running time: 11.230693101882935
learning rate is 0.0005082950737585841
next epoch lr is 0.0005057535983897911, lr_dacay is 0.995


Epoch 136:
Total Loss: 14755.6083984375
Running time: 11.144306659698486
learning rate is 0.0005057535983897911
next epoch lr is 0.0005032248303978422, lr_dacay is 0.995


Epoch 137:
Total Loss: 14704.46875
Running time: 11.489210367202759
learning rate is 0.0005032248303978422
next epoch lr is 0.000500708706245853, lr_dacay is 0.995


Epoch 138:
Total Loss: 14713.53125
Running time: 11.104169130325317
learning rate is 0.000500708706245853
next epoch lr is 0.0004982051627146237, lr_dacay is 0.995


Epoch 139:
Total Loss: 14706.822265625
Running time: 10.709874629974365
learning rate is 0.0004982051627146237
next epoch lr is 0.0004957141369010506, lr_dacay is 0.995


Epoch 140:
Total Loss: 14692.6318359375
Running time: 11.328040599822998
learning rate is 0.0004957141369010506
next epoch lr is 0.0004932355662165453, lr_dacay is 0.995


Epoch 141:
Total Loss: 14669.1318359375
Running time: 11.261525869369507
learning rate is 0.0004932355662165453
next epoch lr is 0.0004907693883854625, lr_dacay is 0.995


Epoch 142:
Total Loss: 14694.1318359375
Running time: 11.327905416488647
learning rate is 0.0004907693883854625
next epoch lr is 0.0004883155414435352, lr_dacay is 0.995


Epoch 143:
Total Loss: 14668.908203125
Running time: 11.300870180130005
learning rate is 0.0004883155414435352
next epoch lr is 0.00048587396373631753, lr_dacay is 0.995


Epoch 144:
Total Loss: 14666.2265625
Running time: 11.193310022354126
learning rate is 0.00048587396373631753
next epoch lr is 0.00048344459391763597, lr_dacay is 0.995


Epoch 145:
Total Loss: 14647.1240234375
Running time: 11.077786207199097
learning rate is 0.00048344459391763597
next epoch lr is 0.0004810273709480478, lr_dacay is 0.995


Epoch 146:
Total Loss: 14678.240234375
Running time: 11.24657392501831
learning rate is 0.0004810273709480478
next epoch lr is 0.00047862223409330756, lr_dacay is 0.995


Epoch 147:
Total Loss: 14656.3828125
Running time: 11.336244821548462
learning rate is 0.00047862223409330756
next epoch lr is 0.000476229122922841, lr_dacay is 0.995


Epoch 148:
Total Loss: 14671.9296875
Running time: 11.067849159240723
learning rate is 0.000476229122922841
next epoch lr is 0.0004738479773082268, lr_dacay is 0.995


Epoch 149:
Total Loss: 14645.169921875
Running time: 11.230940341949463
learning rate is 0.0004738479773082268
next epoch lr is 0.0004714787374216857, lr_dacay is 0.995


Epoch 150:
Total Loss: 14641.9501953125
Running time: 11.16478967666626
learning rate is 0.0004714787374216857
next epoch lr is 0.00046912134373457723, lr_dacay is 0.995


Epoch 151:
Total Loss: 14641.5927734375
Running time: 11.241034746170044
learning rate is 0.00046912134373457723
next epoch lr is 0.00046677573701590436, lr_dacay is 0.995


Epoch 152:
Total Loss: 14638.1611328125
Running time: 11.462610006332397
learning rate is 0.00046677573701590436
next epoch lr is 0.0004644418583308248, lr_dacay is 0.995


Epoch 153:
Total Loss: 14634.244140625
Running time: 11.40039873123169
learning rate is 0.0004644418583308248
next epoch lr is 0.0004621196490391707, lr_dacay is 0.995


Epoch 154:
Total Loss: 14644.482421875
Running time: 11.453906536102295
learning rate is 0.0004621196490391707
next epoch lr is 0.00045980905079397486, lr_dacay is 0.995


Epoch 155:
Total Loss: 14595.8388671875
Running time: 11.138164520263672
learning rate is 0.00045980905079397486
next epoch lr is 0.000457510005540005, lr_dacay is 0.995


Epoch 156:
Total Loss: 14599.90234375
Running time: 11.51454758644104
learning rate is 0.000457510005540005
next epoch lr is 0.00045522245551230493, lr_dacay is 0.995


Epoch 157:
Total Loss: 14622.1396484375
Running time: 11.458436489105225
learning rate is 0.00045522245551230493
next epoch lr is 0.0004529463432347434, lr_dacay is 0.995


Epoch 158:
Total Loss: 14577.599609375
Running time: 11.138556480407715
learning rate is 0.0004529463432347434
next epoch lr is 0.00045068161151856965, lr_dacay is 0.995


Epoch 159:
Total Loss: 14621.5224609375
Running time: 11.55783748626709
learning rate is 0.00045068161151856965
next epoch lr is 0.0004484282034609768, lr_dacay is 0.995


Epoch 160:
Total Loss: 14611.330078125
Running time: 11.59699010848999
learning rate is 0.0004484282034609768
next epoch lr is 0.0004461860624436719, lr_dacay is 0.995


Epoch 161:
Total Loss: 14579.5361328125
Running time: 11.585972547531128
learning rate is 0.0004461860624436719
next epoch lr is 0.00044395513213145357, lr_dacay is 0.995


Epoch 162:
Total Loss: 14595.98046875
Running time: 11.318975925445557
learning rate is 0.00044395513213145357
next epoch lr is 0.0004417353564707963, lr_dacay is 0.995


Epoch 163:
Total Loss: 14603.8759765625
Running time: 11.19683575630188
learning rate is 0.0004417353564707963
next epoch lr is 0.00043952667968844234, lr_dacay is 0.995


Epoch 164:
Total Loss: 14594.283203125
Running time: 11.233391761779785
learning rate is 0.00043952667968844234
next epoch lr is 0.0004373290462900001, lr_dacay is 0.995


Epoch 165:
Total Loss: 14597.591796875
Running time: 11.368152856826782
learning rate is 0.0004373290462900001
next epoch lr is 0.0004351424010585501, lr_dacay is 0.995


Epoch 166:
Total Loss: 14590.0830078125
Running time: 11.602009534835815
learning rate is 0.0004351424010585501
next epoch lr is 0.00043296668905325734, lr_dacay is 0.995


Epoch 167:
Total Loss: 14571.8173828125
Running time: 11.063275337219238
learning rate is 0.00043296668905325734
next epoch lr is 0.00043080185560799106, lr_dacay is 0.995


Epoch 168:
Total Loss: 14592.724609375
Running time: 11.558780193328857
learning rate is 0.00043080185560799106
next epoch lr is 0.0004286478463299511, lr_dacay is 0.995


Epoch 169:
Total Loss: 14557.5927734375
Running time: 11.351426839828491
learning rate is 0.0004286478463299511
next epoch lr is 0.00042650460709830134, lr_dacay is 0.995


Epoch 170:
Total Loss: 14550.8525390625
Running time: 11.449026107788086
learning rate is 0.00042650460709830134
next epoch lr is 0.00042437208406280984, lr_dacay is 0.995


Epoch 171:
Total Loss: 14560.814453125
Running time: 11.614524126052856
learning rate is 0.00042437208406280984
next epoch lr is 0.0004222502236424958, lr_dacay is 0.995


Epoch 172:
Total Loss: 14549.7275390625
Running time: 11.217100143432617
learning rate is 0.0004222502236424958
next epoch lr is 0.0004201389725242833, lr_dacay is 0.995


Epoch 173:
Total Loss: 14556.5
Running time: 11.421781301498413
learning rate is 0.0004201389725242833
next epoch lr is 0.00041803827766166186, lr_dacay is 0.995


Epoch 174:
Total Loss: 14533.5966796875
Running time: 11.335670232772827
learning rate is 0.00041803827766166186
next epoch lr is 0.00041594808627335356, lr_dacay is 0.995


Epoch 175:
Total Loss: 14551.400390625
Running time: 11.281473636627197
learning rate is 0.00041594808627335356
next epoch lr is 0.0004138683458419868, lr_dacay is 0.995


Epoch 176:
Total Loss: 14516.0
Running time: 12.034408807754517
learning rate is 0.0004138683458419868
next epoch lr is 0.00041179900411277687, lr_dacay is 0.995


Epoch 177:
Total Loss: 14498.9091796875
Running time: 12.139945030212402
learning rate is 0.00041179900411277687
next epoch lr is 0.000409740009092213, lr_dacay is 0.995


Epoch 178:
Total Loss: 14535.615234375
Running time: 11.591462135314941
learning rate is 0.000409740009092213
next epoch lr is 0.00040769130904675196, lr_dacay is 0.995


Epoch 179:
Total Loss: 14515.6982421875
Running time: 11.036174058914185
learning rate is 0.00040769130904675196
next epoch lr is 0.0004056528525015182, lr_dacay is 0.995


Epoch 180:
Total Loss: 14496.7841796875
Running time: 11.86915397644043
learning rate is 0.0004056528525015182
next epoch lr is 0.0004036245882390106, lr_dacay is 0.995


Epoch 181:
Total Loss: 14544.62109375
Running time: 11.223265171051025
learning rate is 0.0004036245882390106
next epoch lr is 0.00040160646529781557, lr_dacay is 0.995


Epoch 182:
Total Loss: 14517.8115234375
Running time: 11.347055435180664
learning rate is 0.00040160646529781557
next epoch lr is 0.00039959843297132647, lr_dacay is 0.995


Epoch 183:
Total Loss: 14501.0546875
Running time: 11.515239000320435
learning rate is 0.00039959843297132647
next epoch lr is 0.00039760044080646985, lr_dacay is 0.995


Epoch 184:
Total Loss: 14513.7109375
Running time: 11.322921991348267
learning rate is 0.00039760044080646985
next epoch lr is 0.0003956124386024375, lr_dacay is 0.995


Epoch 185:
Total Loss: 14509.81640625
Running time: 10.926284790039062
learning rate is 0.0003956124386024375
next epoch lr is 0.0003936343764094253, lr_dacay is 0.995


Epoch 186:
Total Loss: 14500.14453125
Running time: 11.236392498016357
learning rate is 0.0003936343764094253
next epoch lr is 0.00039166620452737815, lr_dacay is 0.995


Epoch 187:
Total Loss: 14514.0078125
Running time: 11.262059211730957
learning rate is 0.00039166620452737815
next epoch lr is 0.00038970787350474124, lr_dacay is 0.995


Epoch 188:
Total Loss: 14515.7041015625
Running time: 11.801480770111084
learning rate is 0.00038970787350474124
next epoch lr is 0.0003877593341372175, lr_dacay is 0.995


Epoch 189:
Total Loss: 14511.6962890625
Running time: 11.641163110733032
learning rate is 0.0003877593341372175
next epoch lr is 0.00038582053746653145, lr_dacay is 0.995


Epoch 190:
Total Loss: 14476.53125
Running time: 11.081149339675903
learning rate is 0.00038582053746653145
next epoch lr is 0.0003838914347791988, lr_dacay is 0.995


Epoch 191:
Total Loss: 14483.9306640625
Running time: 11.397879838943481
learning rate is 0.0003838914347791988
next epoch lr is 0.0003819719776053028, lr_dacay is 0.995


Epoch 192:
Total Loss: 14488.474609375
Running time: 11.707233905792236
learning rate is 0.0003819719776053028
next epoch lr is 0.00038006211771727627, lr_dacay is 0.995


Epoch 193:
Total Loss: 14506.6689453125
Running time: 11.780598163604736
learning rate is 0.00038006211771727627
next epoch lr is 0.0003781618071286899, lr_dacay is 0.995


Epoch 194:
Total Loss: 14496.4892578125
Running time: 12.06114912033081
learning rate is 0.0003781618071286899
next epoch lr is 0.00037627099809304647, lr_dacay is 0.995


Epoch 195:
Total Loss: 14464.1494140625
Running time: 11.05701494216919
learning rate is 0.00037627099809304647
next epoch lr is 0.00037438964310258126, lr_dacay is 0.995


Epoch 196:
Total Loss: 14485.572265625
Running time: 11.929452896118164
learning rate is 0.00037438964310258126
next epoch lr is 0.00037251769488706835, lr_dacay is 0.995


Epoch 197:
Total Loss: 14461.91796875
Running time: 11.871772766113281
learning rate is 0.00037251769488706835
next epoch lr is 0.000370655106412633, lr_dacay is 0.995


Epoch 198:
Total Loss: 14466.162109375
Running time: 11.110387563705444
learning rate is 0.000370655106412633
next epoch lr is 0.00036880183088056984, lr_dacay is 0.995


Epoch 199:
Total Loss: 14467.919921875
Running time: 11.44118070602417
learning rate is 0.00036880183088056984
next epoch lr is 0.000366957821726167, lr_dacay is 0.995


Epoch 200:
Total Loss: 14453.1923828125
Running time: 11.702518701553345
learning rate is 0.000366957821726167
next epoch lr is 0.00036512303261753613, lr_dacay is 0.995


Epoch 201:
Total Loss: 14463.34375
Running time: 12.197683334350586
learning rate is 0.00036512303261753613
next epoch lr is 0.00036329741745444845, lr_dacay is 0.995


Epoch 202:
Total Loss: 14467.4501953125
Running time: 11.923967599868774
learning rate is 0.00036329741745444845
next epoch lr is 0.0003614809303671762, lr_dacay is 0.995


Epoch 203:
Total Loss: 14451.66796875
Running time: 11.527496099472046
learning rate is 0.0003614809303671762
next epoch lr is 0.0003596735257153403, lr_dacay is 0.995


Epoch 204:
Total Loss: 14437.7236328125
Running time: 11.045366048812866
learning rate is 0.0003596735257153403
next epoch lr is 0.00035787515808676363, lr_dacay is 0.995


Epoch 205:
Total Loss: 14452.275390625
Running time: 11.273999452590942
learning rate is 0.00035787515808676363
next epoch lr is 0.00035608578229632984, lr_dacay is 0.995


Epoch 206:
Total Loss: 14438.18359375
Running time: 11.274275541305542
learning rate is 0.00035608578229632984
next epoch lr is 0.0003543053533848482, lr_dacay is 0.995


Epoch 207:
Total Loss: 14458.078125
Running time: 11.584997415542603
learning rate is 0.0003543053533848482
next epoch lr is 0.00035253382661792394, lr_dacay is 0.995


Epoch 208:
Total Loss: 14439.3173828125
Running time: 10.927738189697266
learning rate is 0.00035253382661792394
next epoch lr is 0.0003507711574848343, lr_dacay is 0.995


Epoch 209:
Total Loss: 14447.287109375
Running time: 11.039355278015137
learning rate is 0.0003507711574848343
next epoch lr is 0.00034901730169741013, lr_dacay is 0.995


Epoch 210:
Total Loss: 14453.81640625
Running time: 11.030561447143555
learning rate is 0.00034901730169741013
next epoch lr is 0.0003472722151889231, lr_dacay is 0.995


Epoch 211:
Total Loss: 14456.10546875
Running time: 11.202399253845215
learning rate is 0.0003472722151889231
next epoch lr is 0.0003455358541129785, lr_dacay is 0.995


Epoch 212:
Total Loss: 14451.671875
Running time: 11.189285516738892
learning rate is 0.0003455358541129785
next epoch lr is 0.0003438081748424136, lr_dacay is 0.995


Epoch 213:
Total Loss: 14443.8740234375
Running time: 11.134320259094238
learning rate is 0.0003438081748424136
next epoch lr is 0.0003420891339682015, lr_dacay is 0.995


Epoch 214:
Total Loss: 14427.05078125
Running time: 10.816559314727783
learning rate is 0.0003420891339682015
next epoch lr is 0.0003403786882983605, lr_dacay is 0.995


Epoch 215:
Total Loss: 14434.73046875
Running time: 10.977360248565674
learning rate is 0.0003403786882983605
next epoch lr is 0.0003386767948568687, lr_dacay is 0.995


Epoch 216:
Total Loss: 14448.822265625
Running time: 11.251361846923828
learning rate is 0.0003386767948568687
next epoch lr is 0.00033698341088258437, lr_dacay is 0.995


Epoch 217:
Total Loss: 14444.3095703125
Running time: 11.32968544960022
learning rate is 0.00033698341088258437
next epoch lr is 0.00033529849382817143, lr_dacay is 0.995


Epoch 218:
Total Loss: 14452.5712890625
Running time: 11.43947720527649
learning rate is 0.00033529849382817143
next epoch lr is 0.00033362200135903056, lr_dacay is 0.995


Epoch 219:
Total Loss: 14437.4658203125
Running time: 10.94853949546814
learning rate is 0.00033362200135903056
next epoch lr is 0.0003319538913522354, lr_dacay is 0.995


Epoch 220:
Total Loss: 14421.0234375
Running time: 10.986281871795654
learning rate is 0.0003319538913522354
next epoch lr is 0.00033029412189547426, lr_dacay is 0.995


Epoch 221:
Total Loss: 14411.2607421875
Running time: 11.272448778152466
learning rate is 0.00033029412189547426
next epoch lr is 0.0003286426512859969, lr_dacay is 0.995


Epoch 222:
Total Loss: 14408.501953125
Running time: 11.4484281539917
learning rate is 0.0003286426512859969
next epoch lr is 0.0003269994380295669, lr_dacay is 0.995


Epoch 223:
Total Loss: 14387.013671875
Running time: 11.451564073562622
learning rate is 0.0003269994380295669
next epoch lr is 0.0003253644408394191, lr_dacay is 0.995


Epoch 224:
Total Loss: 14409.7021484375
Running time: 11.370360136032104
learning rate is 0.0003253644408394191
next epoch lr is 0.000323737618635222, lr_dacay is 0.995


Epoch 225:
Total Loss: 14417.224609375
Running time: 11.429858922958374
learning rate is 0.000323737618635222
next epoch lr is 0.00032211893054204585, lr_dacay is 0.995


Epoch 226:
Total Loss: 14394.7666015625
Running time: 11.123364210128784
learning rate is 0.00032211893054204585
next epoch lr is 0.0003205083358893356, lr_dacay is 0.995


Epoch 227:
Total Loss: 14408.572265625
Running time: 11.473499059677124
learning rate is 0.0003205083358893356
next epoch lr is 0.0003189057942098889, lr_dacay is 0.995


Epoch 228:
Total Loss: 14424.8271484375
Running time: 11.11762523651123
learning rate is 0.0003189057942098889
next epoch lr is 0.00031731126523883944, lr_dacay is 0.995


Epoch 229:
Total Loss: 14372.19921875
Running time: 11.398234605789185
learning rate is 0.00031731126523883944
next epoch lr is 0.00031572470891264525, lr_dacay is 0.995


Epoch 230:
Total Loss: 14413.7158203125
Running time: 11.403817892074585
learning rate is 0.00031572470891264525
next epoch lr is 0.000314146085368082, lr_dacay is 0.995


Epoch 231:
Total Loss: 14414.365234375
Running time: 11.406109094619751
learning rate is 0.000314146085368082
next epoch lr is 0.0003125753549412416, lr_dacay is 0.995


Epoch 232:
Total Loss: 14401.4501953125
Running time: 11.845999956130981
learning rate is 0.0003125753549412416
next epoch lr is 0.0003110124781665354, lr_dacay is 0.995


Epoch 233:
Total Loss: 14411.2783203125
Running time: 11.301852703094482
learning rate is 0.0003110124781665354
next epoch lr is 0.00030945741577570273, lr_dacay is 0.995


Epoch 234:
Total Loss: 14397.5615234375
Running time: 11.280508995056152
learning rate is 0.00030945741577570273
next epoch lr is 0.0003079101286968242, lr_dacay is 0.995


Epoch 235:
Total Loss: 14390.326171875
Running time: 11.199512481689453
learning rate is 0.0003079101286968242
next epoch lr is 0.0003063705780533401, lr_dacay is 0.995


Epoch 236:
Total Loss: 14367.4736328125
Running time: 11.293718576431274
learning rate is 0.0003063705780533401
next epoch lr is 0.0003048387251630734, lr_dacay is 0.995


Epoch 237:
Total Loss: 14414.1240234375
Running time: 11.146477937698364
learning rate is 0.0003048387251630734
next epoch lr is 0.000303314531537258, lr_dacay is 0.995


Epoch 238:
Total Loss: 14391.9404296875
Running time: 11.178883790969849
learning rate is 0.000303314531537258
next epoch lr is 0.0003017979588795717, lr_dacay is 0.995


Epoch 239:
Total Loss: 14380.6337890625
Running time: 11.293919801712036
learning rate is 0.0003017979588795717
next epoch lr is 0.0003002889690851738, lr_dacay is 0.995


Epoch 240:
Total Loss: 14391.3427734375
Running time: 11.454518556594849
learning rate is 0.0003002889690851738
next epoch lr is 0.000298787524239748, lr_dacay is 0.995


Epoch 241:
Total Loss: 14390.1640625
Running time: 11.42932915687561
learning rate is 0.000298787524239748
next epoch lr is 0.0002972935866185492, lr_dacay is 0.995


Epoch 242:
Total Loss: 14368.548828125
Running time: 11.304693937301636
learning rate is 0.0002972935866185492
next epoch lr is 0.00029580711868545646, lr_dacay is 0.995


Epoch 243:
Total Loss: 14353.173828125
Running time: 11.926310300827026
learning rate is 0.00029580711868545646
next epoch lr is 0.0002943280830920292, lr_dacay is 0.995


Epoch 244:
Total Loss: 14340.12890625
Running time: 11.673552513122559
learning rate is 0.0002943280830920292
next epoch lr is 0.00029285644267656904, lr_dacay is 0.995


Epoch 245:
Total Loss: 14393.3623046875
Running time: 11.775810956954956
learning rate is 0.00029285644267656904
next epoch lr is 0.0002913921604631862, lr_dacay is 0.995


Epoch 246:
Total Loss: 14358.8388671875
Running time: 11.433311462402344
learning rate is 0.0002913921604631862
next epoch lr is 0.00028993519966087026, lr_dacay is 0.995


Epoch 247:
Total Loss: 14403.5302734375
Running time: 11.37675166130066
learning rate is 0.00028993519966087026
next epoch lr is 0.0002884855236625659, lr_dacay is 0.995


Epoch 248:
Total Loss: 14370.666015625
Running time: 11.684456586837769
learning rate is 0.0002884855236625659
next epoch lr is 0.00028704309604425307, lr_dacay is 0.995


Epoch 249:
Total Loss: 14391.25390625
Running time: 11.223142385482788
learning rate is 0.00028704309604425307
next epoch lr is 0.0002856078805640318, lr_dacay is 0.995


Epoch 250:
Total Loss: 14349.0625
Running time: 11.701412916183472
learning rate is 0.0002856078805640318
next epoch lr is 0.0002841798411612116, lr_dacay is 0.995


Epoch 251:
Total Loss: 14421.41015625
Running time: 11.89644455909729
learning rate is 0.0002841798411612116
next epoch lr is 0.0002827589419554055, lr_dacay is 0.995


Epoch 252:
Total Loss: 14371.1494140625
Running time: 11.444807052612305
learning rate is 0.0002827589419554055
next epoch lr is 0.0002813451472456285, lr_dacay is 0.995


Epoch 253:
Total Loss: 14369.6064453125
Running time: 11.277513980865479
learning rate is 0.0002813451472456285
next epoch lr is 0.0002799384215094004, lr_dacay is 0.995


Epoch 254:
Total Loss: 14369.3662109375
Running time: 11.185883522033691
learning rate is 0.0002799384215094004
next epoch lr is 0.00027853872940185336, lr_dacay is 0.995


Epoch 255:
Total Loss: 14368.2578125
Running time: 11.146736145019531
learning rate is 0.00027853872940185336
next epoch lr is 0.0002771460357548441, lr_dacay is 0.995


Epoch 256:
Total Loss: 14340.18359375
Running time: 11.326916217803955
learning rate is 0.0002771460357548441
next epoch lr is 0.0002757603055760699, lr_dacay is 0.995


Epoch 257:
Total Loss: 14365.662109375
Running time: 11.462038278579712
learning rate is 0.0002757603055760699
next epoch lr is 0.0002743815040481895, lr_dacay is 0.995


Epoch 258:
Total Loss: 14373.3134765625
Running time: 11.441757678985596
learning rate is 0.0002743815040481895
next epoch lr is 0.00027300959652794857, lr_dacay is 0.995


Epoch 259:
Total Loss: 14365.9384765625
Running time: 11.259718894958496
learning rate is 0.00027300959652794857
next epoch lr is 0.0002716445485453088, lr_dacay is 0.995


Epoch 260:
Total Loss: 14362.9287109375
Running time: 11.219990730285645
learning rate is 0.0002716445485453088
next epoch lr is 0.0002702863258025823, lr_dacay is 0.995


Epoch 261:
Total Loss: 14374.568359375
Running time: 11.377261638641357
learning rate is 0.0002702863258025823
next epoch lr is 0.00026893489417356936, lr_dacay is 0.995


Epoch 262:
Total Loss: 14371.6953125
Running time: 11.133962392807007
learning rate is 0.00026893489417356936
next epoch lr is 0.0002675902197027015, lr_dacay is 0.995


Epoch 263:
Total Loss: 14343.94921875
Running time: 11.411253452301025
learning rate is 0.0002675902197027015
next epoch lr is 0.000266252268604188, lr_dacay is 0.995


Epoch 264:
Total Loss: 14332.8828125
Running time: 11.039573192596436
learning rate is 0.000266252268604188
next epoch lr is 0.0002649210072611671, lr_dacay is 0.995


Epoch 265:
Total Loss: 14338.810546875
Running time: 10.885769844055176
learning rate is 0.0002649210072611671
next epoch lr is 0.0002635964022248612, lr_dacay is 0.995


Epoch 266:
Total Loss: 14312.7998046875
Running time: 11.20041036605835
learning rate is 0.0002635964022248612
next epoch lr is 0.0002622784202137369, lr_dacay is 0.995


Epoch 267:
Total Loss: 14328.3291015625
Running time: 10.752078771591187
learning rate is 0.0002622784202137369
next epoch lr is 0.00026096702811266825, lr_dacay is 0.995


Epoch 268:
Total Loss: 14351.697265625
Running time: 10.832238674163818
learning rate is 0.00026096702811266825
next epoch lr is 0.0002596621929721049, lr_dacay is 0.995


Epoch 269:
Total Loss: 14348.080078125
Running time: 10.99553370475769
learning rate is 0.0002596621929721049
next epoch lr is 0.0002583638820072444, lr_dacay is 0.995


Epoch 270:
Total Loss: 14353.0703125
Running time: 11.399010181427002
learning rate is 0.0002583638820072444
next epoch lr is 0.00025707206259720813, lr_dacay is 0.995


Epoch 271:
Total Loss: 14354.7373046875
Running time: 11.120113372802734
learning rate is 0.00025707206259720813
next epoch lr is 0.0002557867022842221, lr_dacay is 0.995


Epoch 272:
Total Loss: 14340.068359375
Running time: 11.454901456832886
learning rate is 0.0002557867022842221
next epoch lr is 0.00025450776877280096, lr_dacay is 0.995


Epoch 273:
Total Loss: 14323.15625
Running time: 11.033604145050049
learning rate is 0.00025450776877280096
next epoch lr is 0.00025323522992893693, lr_dacay is 0.995


Epoch 274:
Total Loss: 14336.76953125
Running time: 10.995368003845215
learning rate is 0.00025323522992893693
next epoch lr is 0.00025196905377929227, lr_dacay is 0.995


Epoch 275:
Total Loss: 14315.607421875
Running time: 10.79086947441101
learning rate is 0.00025196905377929227
next epoch lr is 0.0002507092085103958, lr_dacay is 0.995


Epoch 276:
Total Loss: 14335.498046875
Running time: 10.84601354598999
learning rate is 0.0002507092085103958
next epoch lr is 0.0002494556624678438, lr_dacay is 0.995


Epoch 277:
Total Loss: 14358.1513671875
Running time: 11.027650356292725
learning rate is 0.0002494556624678438
next epoch lr is 0.0002482083841555046, lr_dacay is 0.995


Epoch 278:
Total Loss: 14335.9072265625
Running time: 11.10495638847351
learning rate is 0.0002482083841555046
next epoch lr is 0.00024696734223472706, lr_dacay is 0.995


Epoch 279:
Total Loss: 14345.779296875
Running time: 10.89844274520874
learning rate is 0.00024696734223472706
next epoch lr is 0.00024573250552355344, lr_dacay is 0.995


Epoch 280:
Total Loss: 14332.1982421875
Running time: 10.965332508087158
learning rate is 0.00024573250552355344
next epoch lr is 0.00024450384299593567, lr_dacay is 0.995


Epoch 281:
Total Loss: 14321.1748046875
Running time: 10.997676372528076
learning rate is 0.00024450384299593567
next epoch lr is 0.000243281323780956, lr_dacay is 0.995


Epoch 282:
Total Loss: 14305.9697265625
Running time: 10.958951950073242
learning rate is 0.000243281323780956
next epoch lr is 0.0002420649171620512, lr_dacay is 0.995


Epoch 283:
Total Loss: 14342.21875
Running time: 10.969297885894775
learning rate is 0.0002420649171620512
next epoch lr is 0.00024085459257624093, lr_dacay is 0.995


Epoch 284:
Total Loss: 14316.2001953125
Running time: 11.042561054229736
learning rate is 0.00024085459257624093
next epoch lr is 0.00023965031961335973, lr_dacay is 0.995


Epoch 285:
Total Loss: 14333.6083984375
Running time: 10.70087194442749
learning rate is 0.00023965031961335973
next epoch lr is 0.00023845206801529294, lr_dacay is 0.995


Epoch 286:
Total Loss: 14349.9794921875
Running time: 11.065199375152588
learning rate is 0.00023845206801529294
next epoch lr is 0.00023725980767521648, lr_dacay is 0.995


Epoch 287:
Total Loss: 14299.5322265625
Running time: 11.133035659790039
learning rate is 0.00023725980767521648
next epoch lr is 0.00023607350863684038, lr_dacay is 0.995


Epoch 288:
Total Loss: 14319.3662109375
Running time: 11.196476697921753
learning rate is 0.00023607350863684038
next epoch lr is 0.00023489314109365617, lr_dacay is 0.995


Epoch 289:
Total Loss: 14325.271484375
Running time: 11.123671531677246
learning rate is 0.00023489314109365617
next epoch lr is 0.0002337186753881879, lr_dacay is 0.995


Epoch 290:
Total Loss: 14315.525390625
Running time: 11.188493251800537
learning rate is 0.0002337186753881879
next epoch lr is 0.00023255008201124696, lr_dacay is 0.995


Epoch 291:
Total Loss: 14316.599609375
Running time: 11.364147186279297
learning rate is 0.00023255008201124696
next epoch lr is 0.00023138733160119073, lr_dacay is 0.995


Epoch 292:
Total Loss: 14338.365234375
Running time: 11.409919500350952
learning rate is 0.00023138733160119073
next epoch lr is 0.0002302303949431848, lr_dacay is 0.995


Epoch 293:
Total Loss: 14311.39453125
Running time: 11.297134637832642
learning rate is 0.0002302303949431848
next epoch lr is 0.00022907924296846886, lr_dacay is 0.995


Epoch 294:
Total Loss: 14308.4677734375
Running time: 10.937499284744263
learning rate is 0.00022907924296846886
next epoch lr is 0.0002279338467536265, lr_dacay is 0.995


Epoch 295:
Total Loss: 14313.0380859375
Running time: 10.97156548500061
learning rate is 0.0002279338467536265
next epoch lr is 0.00022679417751985838, lr_dacay is 0.995


Epoch 296:
Total Loss: 14303.96875
Running time: 11.197574377059937
learning rate is 0.00022679417751985838
next epoch lr is 0.00022566020663225908, lr_dacay is 0.995


Epoch 297:
Total Loss: 14319.09375
Running time: 11.01733684539795
learning rate is 0.00022566020663225908
next epoch lr is 0.00022453190559909778, lr_dacay is 0.995


Epoch 298:
Total Loss: 14307.951171875
Running time: 11.066561698913574
learning rate is 0.00022453190559909778
next epoch lr is 0.00022340924607110228, lr_dacay is 0.995


Epoch 299:
Total Loss: 14329.5146484375
Running time: 10.974438905715942
learning rate is 0.00022340924607110228
next epoch lr is 0.00022229219984074678, lr_dacay is 0.995


