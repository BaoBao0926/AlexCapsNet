Epoch 0:
Total Loss: 598.3507080078125
Running time: 131.4513556957245
learning rate is 0.001
next epoch lr is 0.000995, lr_dacay is 0.995


Epoch 1:
Total Loss: 529.3965454101562
Running time: 130.88647508621216
learning rate is 0.000995
next epoch lr is 0.000990025, lr_dacay is 0.995


Epoch 2:
Total Loss: 479.9417724609375
Running time: 130.86370539665222
learning rate is 0.000990025
next epoch lr is 0.000985074875, lr_dacay is 0.995


Epoch 3:
Total Loss: 434.45745849609375
Running time: 130.73436498641968
learning rate is 0.000985074875
next epoch lr is 0.000980149500625, lr_dacay is 0.995


Epoch 4:
Total Loss: 390.3944091796875
Running time: 130.839599609375
learning rate is 0.000980149500625
next epoch lr is 0.000975248753121875, lr_dacay is 0.995


Epoch 5:
Total Loss: 344.2017517089844
Running time: 130.7530014514923
learning rate is 0.000975248753121875
next epoch lr is 0.0009703725093562657, lr_dacay is 0.995


Epoch 6:
Total Loss: 298.4231872558594
Running time: 130.84748649597168
learning rate is 0.0009703725093562657
next epoch lr is 0.0009655206468094843, lr_dacay is 0.995


Epoch 7:
Total Loss: 254.20021057128906
Running time: 130.48161149024963
learning rate is 0.0009655206468094843
next epoch lr is 0.0009606930435754369, lr_dacay is 0.995


Epoch 8:
Total Loss: 213.31277465820312
Running time: 130.49733686447144
learning rate is 0.0009606930435754369
next epoch lr is 0.0009558895783575597, lr_dacay is 0.995


Epoch 9:
Total Loss: 176.449951171875
Running time: 130.69882082939148
learning rate is 0.0009558895783575597
next epoch lr is 0.0009511101304657719, lr_dacay is 0.995


Epoch 10:
Total Loss: 144.0962677001953
Running time: 130.87520241737366
learning rate is 0.0009511101304657719
next epoch lr is 0.000946354579813443, lr_dacay is 0.995


Epoch 11:
Total Loss: 117.93022155761719
Running time: 130.92976880073547
learning rate is 0.000946354579813443
next epoch lr is 0.0009416228069143757, lr_dacay is 0.995


Epoch 12:
Total Loss: 96.24430847167969
Running time: 130.77343106269836
learning rate is 0.0009416228069143757
next epoch lr is 0.0009369146928798038, lr_dacay is 0.995


Epoch 13:
Total Loss: 79.17760467529297
Running time: 130.77751684188843
learning rate is 0.0009369146928798038
next epoch lr is 0.0009322301194154048, lr_dacay is 0.995


Epoch 14:
Total Loss: 66.2264633178711
Running time: 130.8325593471527
learning rate is 0.0009322301194154048
next epoch lr is 0.0009275689688183278, lr_dacay is 0.995


Epoch 15:
Total Loss: 55.60043716430664
Running time: 130.30425214767456
learning rate is 0.0009275689688183278
next epoch lr is 0.0009229311239742361, lr_dacay is 0.995


Epoch 16:
Total Loss: 49.1280403137207
Running time: 130.93358945846558
learning rate is 0.0009229311239742361
next epoch lr is 0.0009183164683543649, lr_dacay is 0.995


Epoch 17:
Total Loss: 42.51338577270508
Running time: 130.84720635414124
learning rate is 0.0009183164683543649
next epoch lr is 0.0009137248860125931, lr_dacay is 0.995


Epoch 18:
Total Loss: 37.54051208496094
Running time: 130.94848799705505
learning rate is 0.0009137248860125931
next epoch lr is 0.0009091562615825302, lr_dacay is 0.995


Epoch 19:
Total Loss: 34.07726287841797
Running time: 130.14437747001648
learning rate is 0.0009091562615825302
next epoch lr is 0.0009046104802746175, lr_dacay is 0.995


Epoch 20:
Total Loss: 29.96208381652832
Running time: 130.6041443347931
learning rate is 0.0009046104802746175
next epoch lr is 0.0009000874278732445, lr_dacay is 0.995


Epoch 21:
Total Loss: 28.047780990600586
Running time: 130.31182217597961
learning rate is 0.0009000874278732445
next epoch lr is 0.0008955869907338783, lr_dacay is 0.995


Epoch 22:
Total Loss: 24.826751708984375
Running time: 130.2175440788269
learning rate is 0.0008955869907338783
next epoch lr is 0.0008911090557802089, lr_dacay is 0.995


Epoch 23:
Total Loss: 23.780820846557617
Running time: 130.78187942504883
learning rate is 0.0008911090557802089
next epoch lr is 0.0008866535105013078, lr_dacay is 0.995


Epoch 24:
Total Loss: 22.17232322692871
Running time: 130.75020694732666
learning rate is 0.0008866535105013078
next epoch lr is 0.0008822202429488013, lr_dacay is 0.995


Epoch 25:
Total Loss: 20.21939468383789
Running time: 130.85195636749268
learning rate is 0.0008822202429488013
next epoch lr is 0.0008778091417340573, lr_dacay is 0.995


Epoch 26:
Total Loss: 19.760494232177734
Running time: 130.79867482185364
learning rate is 0.0008778091417340573
next epoch lr is 0.000873420096025387, lr_dacay is 0.995


Epoch 27:
Total Loss: 19.34998321533203
Running time: 130.76460027694702
learning rate is 0.000873420096025387
next epoch lr is 0.0008690529955452601, lr_dacay is 0.995


Epoch 28:
Total Loss: 16.854358673095703
Running time: 130.80157923698425
learning rate is 0.0008690529955452601
next epoch lr is 0.0008647077305675338, lr_dacay is 0.995


Epoch 29:
Total Loss: 16.61961555480957
Running time: 130.8496322631836
learning rate is 0.0008647077305675338
next epoch lr is 0.0008603841919146961, lr_dacay is 0.995


Epoch 30:
Total Loss: 15.614632606506348
Running time: 130.847021818161
learning rate is 0.0008603841919146961
next epoch lr is 0.0008560822709551226, lr_dacay is 0.995


Epoch 31:
Total Loss: 14.404200553894043
Running time: 130.84782910346985
learning rate is 0.0008560822709551226
next epoch lr is 0.000851801859600347, lr_dacay is 0.995


Epoch 32:
Total Loss: 14.278791427612305
Running time: 130.9071614742279
learning rate is 0.000851801859600347
next epoch lr is 0.0008475428503023452, lr_dacay is 0.995


Epoch 33:
Total Loss: 12.86999225616455
Running time: 130.8323152065277
learning rate is 0.0008475428503023452
next epoch lr is 0.0008433051360508335, lr_dacay is 0.995


Epoch 34:
Total Loss: 12.569428443908691
Running time: 130.8456244468689
learning rate is 0.0008433051360508335
next epoch lr is 0.0008390886103705794, lr_dacay is 0.995


Epoch 35:
Total Loss: 12.421892166137695
Running time: 130.81627416610718
learning rate is 0.0008390886103705794
next epoch lr is 0.0008348931673187264, lr_dacay is 0.995


Epoch 36:
Total Loss: 12.191546440124512
Running time: 130.86539959907532
learning rate is 0.0008348931673187264
next epoch lr is 0.0008307187014821328, lr_dacay is 0.995


Epoch 37:
Total Loss: 10.259915351867676
Running time: 130.8373396396637
learning rate is 0.0008307187014821328
next epoch lr is 0.0008265651079747222, lr_dacay is 0.995


Epoch 38:
Total Loss: 10.962043762207031
Running time: 130.81538128852844
learning rate is 0.0008265651079747222
next epoch lr is 0.0008224322824348485, lr_dacay is 0.995


Epoch 39:
Total Loss: 10.307394981384277
Running time: 130.77020525932312
learning rate is 0.0008224322824348485
next epoch lr is 0.0008183201210226743, lr_dacay is 0.995


Epoch 40:
Total Loss: 10.561031341552734
Running time: 130.81952476501465
learning rate is 0.0008183201210226743
next epoch lr is 0.0008142285204175609, lr_dacay is 0.995


Epoch 41:
Total Loss: 9.016336441040039
Running time: 130.81019687652588
learning rate is 0.0008142285204175609
next epoch lr is 0.0008101573778154731, lr_dacay is 0.995


Epoch 42:
Total Loss: 9.266536712646484
Running time: 130.84172129631042
learning rate is 0.0008101573778154731
next epoch lr is 0.0008061065909263957, lr_dacay is 0.995


Epoch 43:
Total Loss: 9.003639221191406
Running time: 130.75357031822205
learning rate is 0.0008061065909263957
next epoch lr is 0.0008020760579717638, lr_dacay is 0.995


Epoch 44:
Total Loss: 8.381936073303223
Running time: 130.7726695537567
learning rate is 0.0008020760579717638
next epoch lr is 0.000798065677681905, lr_dacay is 0.995


Epoch 45:
Total Loss: 8.207743644714355
Running time: 130.82650804519653
learning rate is 0.000798065677681905
next epoch lr is 0.0007940753492934955, lr_dacay is 0.995


Epoch 46:
Total Loss: 8.09986686706543
Running time: 130.7974829673767
learning rate is 0.0007940753492934955
next epoch lr is 0.000790104972547028, lr_dacay is 0.995


Epoch 47:
Total Loss: 7.57664155960083
Running time: 130.8447561264038
learning rate is 0.000790104972547028
next epoch lr is 0.0007861544476842928, lr_dacay is 0.995


Epoch 48:
Total Loss: 7.0953898429870605
Running time: 130.79317259788513
learning rate is 0.0007861544476842928
next epoch lr is 0.0007822236754458713, lr_dacay is 0.995


Epoch 49:
Total Loss: 7.023283004760742
Running time: 130.7776644229889
learning rate is 0.0007822236754458713
next epoch lr is 0.0007783125570686419, lr_dacay is 0.995


Epoch 50:
Total Loss: 7.4226579666137695
Running time: 130.75503969192505
learning rate is 0.0007783125570686419
next epoch lr is 0.0007744209942832988, lr_dacay is 0.995


Epoch 51:
Total Loss: 5.8767547607421875
Running time: 130.71128177642822
learning rate is 0.0007744209942832988
next epoch lr is 0.0007705488893118823, lr_dacay is 0.995


Epoch 52:
Total Loss: 6.30756950378418
Running time: 130.80140161514282
learning rate is 0.0007705488893118823
next epoch lr is 0.0007666961448653228, lr_dacay is 0.995


Epoch 53:
Total Loss: 6.576239109039307
Running time: 130.9697663784027
learning rate is 0.0007666961448653228
next epoch lr is 0.0007628626641409962, lr_dacay is 0.995


Epoch 54:
Total Loss: 6.0486907958984375
Running time: 130.9447946548462
learning rate is 0.0007628626641409962
next epoch lr is 0.0007590483508202912, lr_dacay is 0.995


Epoch 55:
Total Loss: 5.6976470947265625
Running time: 130.90127301216125
learning rate is 0.0007590483508202912
next epoch lr is 0.0007552531090661898, lr_dacay is 0.995


Epoch 56:
Total Loss: 6.037935733795166
Running time: 130.88587403297424
learning rate is 0.0007552531090661898
next epoch lr is 0.0007514768435208588, lr_dacay is 0.995


Epoch 57:
Total Loss: 5.150794982910156
Running time: 130.81409883499146
learning rate is 0.0007514768435208588
next epoch lr is 0.0007477194593032545, lr_dacay is 0.995


Epoch 58:
Total Loss: 5.433321952819824
Running time: 130.67036032676697
learning rate is 0.0007477194593032545
next epoch lr is 0.0007439808620067382, lr_dacay is 0.995


Epoch 59:
Total Loss: 5.631484508514404
Running time: 130.57059741020203
learning rate is 0.0007439808620067382
next epoch lr is 0.0007402609576967046, lr_dacay is 0.995


Epoch 60:
Total Loss: 4.592816352844238
Running time: 130.7512276172638
learning rate is 0.0007402609576967046
next epoch lr is 0.000736559652908221, lr_dacay is 0.995


Epoch 61:
Total Loss: 4.6640777587890625
Running time: 130.8742072582245
learning rate is 0.000736559652908221
next epoch lr is 0.0007328768546436799, lr_dacay is 0.995


Epoch 62:
Total Loss: 4.742365837097168
Running time: 130.80610179901123
learning rate is 0.0007328768546436799
next epoch lr is 0.0007292124703704615, lr_dacay is 0.995


Epoch 63:
Total Loss: 4.412899494171143
Running time: 130.77650022506714
learning rate is 0.0007292124703704615
next epoch lr is 0.0007255664080186091, lr_dacay is 0.995


Epoch 64:
Total Loss: 4.380424499511719
Running time: 130.89524793624878
learning rate is 0.0007255664080186091
next epoch lr is 0.0007219385759785161, lr_dacay is 0.995


Epoch 65:
Total Loss: 4.285486221313477
Running time: 130.89050889015198
learning rate is 0.0007219385759785161
next epoch lr is 0.0007183288830986235, lr_dacay is 0.995


Epoch 66:
Total Loss: 4.236627578735352
Running time: 130.82707953453064
learning rate is 0.0007183288830986235
next epoch lr is 0.0007147372386831303, lr_dacay is 0.995


Epoch 67:
Total Loss: 3.7324020862579346
Running time: 130.85184693336487
learning rate is 0.0007147372386831303
next epoch lr is 0.0007111635524897147, lr_dacay is 0.995


Epoch 68:
Total Loss: 4.512796878814697
Running time: 130.85704946517944
learning rate is 0.0007111635524897147
next epoch lr is 0.0007076077347272661, lr_dacay is 0.995


Epoch 69:
Total Loss: 3.6448068618774414
Running time: 130.78184247016907
learning rate is 0.0007076077347272661
next epoch lr is 0.0007040696960536298, lr_dacay is 0.995


Epoch 70:
Total Loss: 4.0294294357299805
Running time: 130.82931685447693
learning rate is 0.0007040696960536298
next epoch lr is 0.0007005493475733617, lr_dacay is 0.995


Epoch 71:
Total Loss: 3.270512342453003
Running time: 130.15608525276184
learning rate is 0.0007005493475733617
next epoch lr is 0.0006970466008354948, lr_dacay is 0.995


Epoch 72:
Total Loss: 3.970205545425415
Running time: 130.49440693855286
learning rate is 0.0006970466008354948
next epoch lr is 0.0006935613678313174, lr_dacay is 0.995


Epoch 73:
Total Loss: 3.382749080657959
Running time: 130.28860521316528
learning rate is 0.0006935613678313174
next epoch lr is 0.0006900935609921607, lr_dacay is 0.995


Epoch 74:
Total Loss: 3.5476717948913574
Running time: 130.4148669242859
learning rate is 0.0006900935609921607
next epoch lr is 0.0006866430931872, lr_dacay is 0.995


Epoch 75:
Total Loss: 3.018272638320923
Running time: 130.33623337745667
learning rate is 0.0006866430931872
next epoch lr is 0.000683209877721264, lr_dacay is 0.995


Epoch 76:
Total Loss: 3.2785494327545166
Running time: 130.45439982414246
learning rate is 0.000683209877721264
next epoch lr is 0.0006797938283326577, lr_dacay is 0.995


Epoch 77:
Total Loss: 3.445624589920044
Running time: 130.35306024551392
learning rate is 0.0006797938283326577
next epoch lr is 0.0006763948591909945, lr_dacay is 0.995


Epoch 78:
Total Loss: 3.0934228897094727
Running time: 130.4238314628601
learning rate is 0.0006763948591909945
next epoch lr is 0.0006730128848950395, lr_dacay is 0.995


Epoch 79:
Total Loss: 2.5663278102874756
Running time: 130.3459873199463
learning rate is 0.0006730128848950395
next epoch lr is 0.0006696478204705643, lr_dacay is 0.995


Epoch 80:
Total Loss: 2.8331685066223145
Running time: 130.73352217674255
learning rate is 0.0006696478204705643
next epoch lr is 0.0006662995813682115, lr_dacay is 0.995


Epoch 81:
Total Loss: 3.364959716796875
Running time: 130.78681683540344
learning rate is 0.0006662995813682115
next epoch lr is 0.0006629680834613704, lr_dacay is 0.995


Epoch 82:
Total Loss: 2.2245190143585205
Running time: 130.82273960113525
learning rate is 0.0006629680834613704
next epoch lr is 0.0006596532430440636, lr_dacay is 0.995


Epoch 83:
Total Loss: 2.991192102432251
Running time: 130.7733588218689
learning rate is 0.0006596532430440636
next epoch lr is 0.0006563549768288432, lr_dacay is 0.995


Epoch 84:
Total Loss: 2.961946487426758
Running time: 130.80064964294434
learning rate is 0.0006563549768288432
next epoch lr is 0.000653073201944699, lr_dacay is 0.995


Epoch 85:
Total Loss: 2.622267723083496
Running time: 130.92954802513123
learning rate is 0.000653073201944699
next epoch lr is 0.0006498078359349755, lr_dacay is 0.995


Epoch 86:
Total Loss: 3.2467265129089355
Running time: 130.8949954509735
learning rate is 0.0006498078359349755
next epoch lr is 0.0006465587967553006, lr_dacay is 0.995


Epoch 87:
Total Loss: 2.138512134552002
Running time: 130.79796075820923
learning rate is 0.0006465587967553006
next epoch lr is 0.0006433260027715241, lr_dacay is 0.995


Epoch 88:
Total Loss: 2.6457910537719727
Running time: 130.80686593055725
learning rate is 0.0006433260027715241
next epoch lr is 0.0006401093727576665, lr_dacay is 0.995


Epoch 89:
Total Loss: 2.2403151988983154
Running time: 130.75885105133057
learning rate is 0.0006401093727576665
next epoch lr is 0.0006369088258938781, lr_dacay is 0.995


Epoch 90:
Total Loss: 1.9326506853103638
Running time: 130.7950370311737
learning rate is 0.0006369088258938781
next epoch lr is 0.0006337242817644087, lr_dacay is 0.995


Epoch 91:
Total Loss: 2.8296802043914795
Running time: 130.81926441192627
learning rate is 0.0006337242817644087
next epoch lr is 0.0006305556603555866, lr_dacay is 0.995


Epoch 92:
Total Loss: 2.2981791496276855
Running time: 130.27601885795593
learning rate is 0.0006305556603555866
next epoch lr is 0.0006274028820538087, lr_dacay is 0.995


Epoch 93:
Total Loss: 2.0120506286621094
Running time: 130.83693027496338
learning rate is 0.0006274028820538087
next epoch lr is 0.0006242658676435396, lr_dacay is 0.995


Epoch 94:
Total Loss: 2.4095163345336914
Running time: 130.8112404346466
learning rate is 0.0006242658676435396
next epoch lr is 0.0006211445383053219, lr_dacay is 0.995


Epoch 95:
Total Loss: 1.9381123781204224
Running time: 130.831848859787
learning rate is 0.0006211445383053219
next epoch lr is 0.0006180388156137953, lr_dacay is 0.995


Epoch 96:
Total Loss: 1.9804126024246216
Running time: 129.99842953681946
learning rate is 0.0006180388156137953
next epoch lr is 0.0006149486215357262, lr_dacay is 0.995


Epoch 97:
Total Loss: 2.2061665058135986
Running time: 130.0223686695099
learning rate is 0.0006149486215357262
next epoch lr is 0.0006118738784280476, lr_dacay is 0.995


Epoch 98:
Total Loss: 2.038784980773926
Running time: 130.29350018501282
learning rate is 0.0006118738784280476
next epoch lr is 0.0006088145090359073, lr_dacay is 0.995


Epoch 99:
Total Loss: 1.84840726852417
Running time: 130.8159761428833
learning rate is 0.0006088145090359073
next epoch lr is 0.0006057704364907278, lr_dacay is 0.995


Epoch 100:
Total Loss: 2.1405029296875
Running time: 130.81347751617432
learning rate is 0.0006057704364907278
next epoch lr is 0.0006027415843082742, lr_dacay is 0.995


Epoch 101:
Total Loss: 1.7362425327301025
Running time: 130.8369243144989
learning rate is 0.0006027415843082742
next epoch lr is 0.0005997278763867329, lr_dacay is 0.995


Epoch 102:
Total Loss: 1.9194077253341675
Running time: 130.8156545162201
learning rate is 0.0005997278763867329
next epoch lr is 0.0005967292370047993, lr_dacay is 0.995


Epoch 103:
Total Loss: 1.8607820272445679
Running time: 130.80019688606262
learning rate is 0.0005967292370047993
next epoch lr is 0.0005937455908197753, lr_dacay is 0.995


Epoch 104:
Total Loss: 1.9637075662612915
Running time: 130.8164577484131
learning rate is 0.0005937455908197753
next epoch lr is 0.0005907768628656764, lr_dacay is 0.995


Epoch 105:
Total Loss: 1.3915375471115112
Running time: 130.75387454032898
learning rate is 0.0005907768628656764
next epoch lr is 0.000587822978551348, lr_dacay is 0.995


Epoch 106:
Total Loss: 1.8155814409255981
Running time: 130.82067275047302
learning rate is 0.000587822978551348
next epoch lr is 0.0005848838636585913, lr_dacay is 0.995


Epoch 107:
Total Loss: 1.8714181184768677
Running time: 130.74746751785278
learning rate is 0.0005848838636585913
next epoch lr is 0.0005819594443402983, lr_dacay is 0.995


Epoch 108:
Total Loss: 1.6407158374786377
Running time: 130.7400312423706
learning rate is 0.0005819594443402983
next epoch lr is 0.0005790496471185969, lr_dacay is 0.995


Epoch 109:
Total Loss: 1.637198805809021
Running time: 130.76467490196228
learning rate is 0.0005790496471185969
next epoch lr is 0.0005761543988830039, lr_dacay is 0.995


Epoch 110:
Total Loss: 1.5361199378967285
Running time: 130.8730707168579
learning rate is 0.0005761543988830039
next epoch lr is 0.0005732736268885889, lr_dacay is 0.995


Epoch 111:
Total Loss: 1.4026633501052856
Running time: 130.70845293998718
learning rate is 0.0005732736268885889
next epoch lr is 0.0005704072587541459, lr_dacay is 0.995


Epoch 112:
Total Loss: 1.7568705081939697
Running time: 130.81034588813782
learning rate is 0.0005704072587541459
next epoch lr is 0.0005675552224603752, lr_dacay is 0.995


Epoch 113:
Total Loss: 1.701817512512207
Running time: 130.76119756698608
learning rate is 0.0005675552224603752
next epoch lr is 0.0005647174463480733, lr_dacay is 0.995


Epoch 114:
Total Loss: 1.272594928741455
Running time: 130.74381566047668
learning rate is 0.0005647174463480733
next epoch lr is 0.0005618938591163329, lr_dacay is 0.995


Epoch 115:
Total Loss: 1.4885916709899902
Running time: 130.7602026462555
learning rate is 0.0005618938591163329
next epoch lr is 0.0005590843898207513, lr_dacay is 0.995


Epoch 116:
Total Loss: 1.3788769245147705
Running time: 130.7971682548523
learning rate is 0.0005590843898207513
next epoch lr is 0.0005562889678716475, lr_dacay is 0.995


Epoch 117:
Total Loss: 1.3894563913345337
Running time: 130.78139185905457
learning rate is 0.0005562889678716475
next epoch lr is 0.0005535075230322892, lr_dacay is 0.995


Epoch 118:
Total Loss: 1.6337180137634277
Running time: 130.73772883415222
learning rate is 0.0005535075230322892
next epoch lr is 0.0005507399854171277, lr_dacay is 0.995


Epoch 119:
Total Loss: 1.3580368757247925
Running time: 130.8007845878601
learning rate is 0.0005507399854171277
next epoch lr is 0.0005479862854900421, lr_dacay is 0.995


Epoch 120:
Total Loss: 1.348673939704895
Running time: 130.72808527946472
learning rate is 0.0005479862854900421
next epoch lr is 0.0005452463540625918, lr_dacay is 0.995


Epoch 121:
Total Loss: 1.2203645706176758
Running time: 130.74278211593628
learning rate is 0.0005452463540625918
next epoch lr is 0.0005425201222922788, lr_dacay is 0.995


Epoch 122:
Total Loss: 1.1933467388153076
Running time: 130.871648311615
learning rate is 0.0005425201222922788
next epoch lr is 0.0005398075216808175, lr_dacay is 0.995


Epoch 123:
Total Loss: 1.3230352401733398
Running time: 130.74969267845154
learning rate is 0.0005398075216808175
next epoch lr is 0.0005371084840724133, lr_dacay is 0.995


Epoch 124:
Total Loss: 1.2403532266616821
Running time: 130.84116435050964
learning rate is 0.0005371084840724133
next epoch lr is 0.0005344229416520513, lr_dacay is 0.995


Epoch 125:
Total Loss: 1.0622000694274902
Running time: 130.7196228504181
learning rate is 0.0005344229416520513
next epoch lr is 0.000531750826943791, lr_dacay is 0.995


Epoch 126:
Total Loss: 1.230891466140747
Running time: 130.47868275642395
learning rate is 0.000531750826943791
next epoch lr is 0.000529092072809072, lr_dacay is 0.995


Epoch 127:
Total Loss: 1.2187007665634155
Running time: 130.25690960884094
learning rate is 0.000529092072809072
next epoch lr is 0.0005264466124450266, lr_dacay is 0.995


Epoch 128:
Total Loss: 1.2316628694534302
Running time: 130.37491703033447
learning rate is 0.0005264466124450266
next epoch lr is 0.0005238143793828015, lr_dacay is 0.995


Epoch 129:
Total Loss: 1.1479545831680298
Running time: 130.23603677749634
learning rate is 0.0005238143793828015
next epoch lr is 0.0005211953074858875, lr_dacay is 0.995


Epoch 130:
Total Loss: 0.9429939389228821
Running time: 130.33841967582703
learning rate is 0.0005211953074858875
next epoch lr is 0.0005185893309484581, lr_dacay is 0.995


Epoch 131:
Total Loss: 1.0996071100234985
Running time: 130.35585832595825
learning rate is 0.0005185893309484581
next epoch lr is 0.0005159963842937158, lr_dacay is 0.995


Epoch 132:
Total Loss: 1.1992276906967163
Running time: 130.38092803955078
learning rate is 0.0005159963842937158
next epoch lr is 0.0005134164023722472, lr_dacay is 0.995


Epoch 133:
Total Loss: 1.3564246892929077
Running time: 130.3576295375824
learning rate is 0.0005134164023722472
next epoch lr is 0.000510849320360386, lr_dacay is 0.995


Epoch 134:
Total Loss: 0.9020604491233826
Running time: 130.3371844291687
learning rate is 0.000510849320360386
next epoch lr is 0.0005082950737585841, lr_dacay is 0.995


Epoch 135:
Total Loss: 0.8795108795166016
Running time: 130.34650349617004
learning rate is 0.0005082950737585841
next epoch lr is 0.0005057535983897911, lr_dacay is 0.995


Epoch 136:
Total Loss: 1.3151462078094482
Running time: 130.20456719398499
learning rate is 0.0005057535983897911
next epoch lr is 0.0005032248303978422, lr_dacay is 0.995


Epoch 137:
Total Loss: 1.1199946403503418
Running time: 130.3624563217163
learning rate is 0.0005032248303978422
next epoch lr is 0.000500708706245853, lr_dacay is 0.995


Epoch 138:
Total Loss: 1.0702154636383057
Running time: 130.3119351863861
learning rate is 0.000500708706245853
next epoch lr is 0.0004982051627146237, lr_dacay is 0.995


Epoch 139:
Total Loss: 0.7530280947685242
Running time: 130.46243262290955
learning rate is 0.0004982051627146237
next epoch lr is 0.0004957141369010506, lr_dacay is 0.995


Epoch 140:
Total Loss: 0.824930727481842
Running time: 130.56140089035034
learning rate is 0.0004957141369010506
next epoch lr is 0.0004932355662165453, lr_dacay is 0.995


Epoch 141:
Total Loss: 1.051114797592163
Running time: 130.28187942504883
learning rate is 0.0004932355662165453
next epoch lr is 0.0004907693883854625, lr_dacay is 0.995


Epoch 142:
Total Loss: 0.981231689453125
Running time: 130.25185799598694
learning rate is 0.0004907693883854625
next epoch lr is 0.0004883155414435352, lr_dacay is 0.995


Epoch 143:
Total Loss: 0.8925707936286926
Running time: 130.29595470428467
learning rate is 0.0004883155414435352
next epoch lr is 0.00048587396373631753, lr_dacay is 0.995


Epoch 144:
Total Loss: 0.8536755442619324
Running time: 130.38182377815247
learning rate is 0.00048587396373631753
next epoch lr is 0.00048344459391763597, lr_dacay is 0.995


Epoch 145:
Total Loss: 0.9039281606674194
Running time: 130.44115805625916
learning rate is 0.00048344459391763597
next epoch lr is 0.0004810273709480478, lr_dacay is 0.995


Epoch 146:
Total Loss: 0.9241563677787781
Running time: 130.41371035575867
learning rate is 0.0004810273709480478
next epoch lr is 0.00047862223409330756, lr_dacay is 0.995


Epoch 147:
Total Loss: 0.9034816026687622
Running time: 130.27798461914062
learning rate is 0.00047862223409330756
next epoch lr is 0.000476229122922841, lr_dacay is 0.995


Epoch 148:
Total Loss: 0.9722690582275391
Running time: 130.55491375923157
learning rate is 0.000476229122922841
next epoch lr is 0.0004738479773082268, lr_dacay is 0.995


Epoch 149:
Total Loss: 0.7443519830703735
Running time: 130.48239398002625
learning rate is 0.0004738479773082268
next epoch lr is 0.0004714787374216857, lr_dacay is 0.995


Epoch 150:
Total Loss: 0.9167279601097107
Running time: 130.58381867408752
learning rate is 0.0004714787374216857
next epoch lr is 0.00046912134373457723, lr_dacay is 0.995


Epoch 151:
Total Loss: 0.7653663754463196
Running time: 130.33452773094177
learning rate is 0.00046912134373457723
next epoch lr is 0.00046677573701590436, lr_dacay is 0.995


Epoch 152:
Total Loss: 0.8480423092842102
Running time: 130.44760537147522
learning rate is 0.00046677573701590436
next epoch lr is 0.0004644418583308248, lr_dacay is 0.995


Epoch 153:
Total Loss: 0.7884382605552673
Running time: 130.4086730480194
learning rate is 0.0004644418583308248
next epoch lr is 0.0004621196490391707, lr_dacay is 0.995


Epoch 154:
Total Loss: 0.695634126663208
Running time: 130.46872735023499
learning rate is 0.0004621196490391707
next epoch lr is 0.00045980905079397486, lr_dacay is 0.995


Epoch 155:
Total Loss: 0.7045940160751343
Running time: 130.35293316841125
learning rate is 0.00045980905079397486
next epoch lr is 0.000457510005540005, lr_dacay is 0.995


Epoch 156:
Total Loss: 0.8773708343505859
Running time: 130.350248336792
learning rate is 0.000457510005540005
next epoch lr is 0.00045522245551230493, lr_dacay is 0.995


Epoch 157:
Total Loss: 0.7358056902885437
Running time: 130.55916213989258
learning rate is 0.00045522245551230493
next epoch lr is 0.0004529463432347434, lr_dacay is 0.995


Epoch 158:
Total Loss: 0.5950114727020264
Running time: 130.299786567688
learning rate is 0.0004529463432347434
next epoch lr is 0.00045068161151856965, lr_dacay is 0.995


Epoch 159:
Total Loss: 0.9078868627548218
Running time: 130.40672087669373
learning rate is 0.00045068161151856965
next epoch lr is 0.0004484282034609768, lr_dacay is 0.995


Epoch 160:
Total Loss: 0.6368928551673889
Running time: 130.33135271072388
learning rate is 0.0004484282034609768
next epoch lr is 0.0004461860624436719, lr_dacay is 0.995


Epoch 161:
Total Loss: 0.7326299548149109
Running time: 130.3949429988861
learning rate is 0.0004461860624436719
next epoch lr is 0.00044395513213145357, lr_dacay is 0.995


Epoch 162:
Total Loss: 0.9263656139373779
Running time: 130.47208881378174
learning rate is 0.00044395513213145357
next epoch lr is 0.0004417353564707963, lr_dacay is 0.995


Epoch 163:
Total Loss: 0.5499098896980286
Running time: 130.40568256378174
learning rate is 0.0004417353564707963
next epoch lr is 0.00043952667968844234, lr_dacay is 0.995


Epoch 164:
Total Loss: 0.6718569397926331
Running time: 130.5166928768158
learning rate is 0.00043952667968844234
next epoch lr is 0.0004373290462900001, lr_dacay is 0.995


Epoch 165:
Total Loss: 0.6094085574150085
Running time: 130.41769671440125
learning rate is 0.0004373290462900001
next epoch lr is 0.0004351424010585501, lr_dacay is 0.995


Epoch 166:
Total Loss: 0.7017473578453064
Running time: 130.295024394989
learning rate is 0.0004351424010585501
next epoch lr is 0.00043296668905325734, lr_dacay is 0.995


Epoch 167:
Total Loss: 0.5682535171508789
Running time: 130.28191423416138
learning rate is 0.00043296668905325734
next epoch lr is 0.00043080185560799106, lr_dacay is 0.995


Epoch 168:
Total Loss: 0.626878023147583
Running time: 130.2005398273468
learning rate is 0.00043080185560799106
next epoch lr is 0.0004286478463299511, lr_dacay is 0.995


Epoch 169:
Total Loss: 0.6852515339851379
Running time: 130.34514904022217
learning rate is 0.0004286478463299511
next epoch lr is 0.00042650460709830134, lr_dacay is 0.995


Epoch 170:
Total Loss: 0.6412796378135681
Running time: 130.1625051498413
learning rate is 0.00042650460709830134
next epoch lr is 0.00042437208406280984, lr_dacay is 0.995


Epoch 171:
Total Loss: 0.4634668529033661
Running time: 130.33037042617798
learning rate is 0.00042437208406280984
next epoch lr is 0.0004222502236424958, lr_dacay is 0.995


Epoch 172:
Total Loss: 0.8220435976982117
Running time: 130.39936876296997
learning rate is 0.0004222502236424958
next epoch lr is 0.0004201389725242833, lr_dacay is 0.995


Epoch 173:
Total Loss: 0.46529075503349304
Running time: 130.29455637931824
learning rate is 0.0004201389725242833
next epoch lr is 0.00041803827766166186, lr_dacay is 0.995


Epoch 174:
Total Loss: 0.5256637334823608
Running time: 130.03910207748413
learning rate is 0.00041803827766166186
next epoch lr is 0.00041594808627335356, lr_dacay is 0.995


Epoch 175:
Total Loss: 0.5065304040908813
Running time: 130.00737166404724
learning rate is 0.00041594808627335356
next epoch lr is 0.0004138683458419868, lr_dacay is 0.995


Epoch 176:
Total Loss: 0.627687931060791
Running time: 130.18069410324097
learning rate is 0.0004138683458419868
next epoch lr is 0.00041179900411277687, lr_dacay is 0.995


Epoch 177:
Total Loss: 0.5989896655082703
Running time: 130.1728003025055
learning rate is 0.00041179900411277687
next epoch lr is 0.000409740009092213, lr_dacay is 0.995


Epoch 178:
Total Loss: 0.5339958667755127
Running time: 130.47808003425598
learning rate is 0.000409740009092213
next epoch lr is 0.00040769130904675196, lr_dacay is 0.995


Epoch 179:
Total Loss: 0.6857156753540039
Running time: 130.19844007492065
learning rate is 0.00040769130904675196
next epoch lr is 0.0004056528525015182, lr_dacay is 0.995


Epoch 180:
Total Loss: 0.38136136531829834
Running time: 130.25414085388184
learning rate is 0.0004056528525015182
next epoch lr is 0.0004036245882390106, lr_dacay is 0.995


Epoch 181:
Total Loss: 0.49308085441589355
Running time: 130.39750719070435
learning rate is 0.0004036245882390106
next epoch lr is 0.00040160646529781557, lr_dacay is 0.995


Epoch 182:
Total Loss: 0.5164774060249329
Running time: 130.08648228645325
learning rate is 0.00040160646529781557
next epoch lr is 0.00039959843297132647, lr_dacay is 0.995


Epoch 183:
Total Loss: 0.5462235808372498
Running time: 130.28014659881592
learning rate is 0.00039959843297132647
next epoch lr is 0.00039760044080646985, lr_dacay is 0.995


Epoch 184:
Total Loss: 0.5605485439300537
Running time: 130.30213904380798
learning rate is 0.00039760044080646985
next epoch lr is 0.0003956124386024375, lr_dacay is 0.995


Epoch 185:
Total Loss: 0.4284355640411377
Running time: 130.29671955108643
learning rate is 0.0003956124386024375
next epoch lr is 0.0003936343764094253, lr_dacay is 0.995


Epoch 186:
Total Loss: 0.3975145220756531
Running time: 130.34014010429382
learning rate is 0.0003936343764094253
next epoch lr is 0.00039166620452737815, lr_dacay is 0.995


Epoch 187:
Total Loss: 0.41274234652519226
Running time: 130.49101066589355
learning rate is 0.00039166620452737815
next epoch lr is 0.00038970787350474124, lr_dacay is 0.995


Epoch 188:
Total Loss: 0.5732827186584473
Running time: 130.31921768188477
learning rate is 0.00038970787350474124
next epoch lr is 0.0003877593341372175, lr_dacay is 0.995


Epoch 189:
Total Loss: 0.5689318776130676
Running time: 130.52501511573792
learning rate is 0.0003877593341372175
next epoch lr is 0.00038582053746653145, lr_dacay is 0.995


Epoch 190:
Total Loss: 0.42661839723587036
Running time: 130.40407848358154
learning rate is 0.00038582053746653145
next epoch lr is 0.0003838914347791988, lr_dacay is 0.995


Epoch 191:
Total Loss: 0.46460458636283875
Running time: 130.25646710395813
learning rate is 0.0003838914347791988
next epoch lr is 0.0003819719776053028, lr_dacay is 0.995


Epoch 192:
Total Loss: 0.4176928400993347
Running time: 130.2991979122162
learning rate is 0.0003819719776053028
next epoch lr is 0.00038006211771727627, lr_dacay is 0.995


Epoch 193:
Total Loss: 0.4283454418182373
Running time: 130.21079802513123
learning rate is 0.00038006211771727627
next epoch lr is 0.0003781618071286899, lr_dacay is 0.995


Epoch 194:
Total Loss: 0.46055087447166443
Running time: 130.3825478553772
learning rate is 0.0003781618071286899
next epoch lr is 0.00037627099809304647, lr_dacay is 0.995


Epoch 195:
Total Loss: 0.5015456676483154
Running time: 130.2042112350464
learning rate is 0.00037627099809304647
next epoch lr is 0.00037438964310258126, lr_dacay is 0.995


Epoch 196:
Total Loss: 0.3389047384262085
Running time: 130.0820529460907
learning rate is 0.00037438964310258126
next epoch lr is 0.00037251769488706835, lr_dacay is 0.995


Epoch 197:
Total Loss: 0.33696964383125305
Running time: 130.03096508979797
learning rate is 0.00037251769488706835
next epoch lr is 0.000370655106412633, lr_dacay is 0.995


Epoch 198:
Total Loss: 0.5508208274841309
Running time: 130.38448667526245
learning rate is 0.000370655106412633
next epoch lr is 0.00036880183088056984, lr_dacay is 0.995


Epoch 199:
Total Loss: 0.4000132083892822
Running time: 130.25770735740662
learning rate is 0.00036880183088056984
next epoch lr is 0.000366957821726167, lr_dacay is 0.995


Epoch 200:
Total Loss: 0.4014834463596344
Running time: 130.08607649803162
learning rate is 0.000366957821726167
next epoch lr is 0.00036512303261753613, lr_dacay is 0.995


Epoch 201:
Total Loss: 0.5185505747795105
Running time: 130.27463793754578
learning rate is 0.00036512303261753613
next epoch lr is 0.00036329741745444845, lr_dacay is 0.995


Epoch 202:
Total Loss: 0.37865254282951355
Running time: 130.23036336898804
learning rate is 0.00036329741745444845
next epoch lr is 0.0003614809303671762, lr_dacay is 0.995


Epoch 203:
Total Loss: 0.3934449255466461
Running time: 130.20378136634827
learning rate is 0.0003614809303671762
next epoch lr is 0.0003596735257153403, lr_dacay is 0.995


Epoch 204:
Total Loss: 0.4373624920845032
Running time: 130.17500400543213
learning rate is 0.0003596735257153403
next epoch lr is 0.00035787515808676363, lr_dacay is 0.995


Epoch 205:
Total Loss: 0.36865052580833435
Running time: 130.00251460075378
learning rate is 0.00035787515808676363
next epoch lr is 0.00035608578229632984, lr_dacay is 0.995


Epoch 206:
Total Loss: 0.39872419834136963
Running time: 130.25178456306458
learning rate is 0.00035608578229632984
next epoch lr is 0.0003543053533848482, lr_dacay is 0.995


Epoch 207:
Total Loss: 0.4020881950855255
Running time: 130.18404126167297
learning rate is 0.0003543053533848482
next epoch lr is 0.00035253382661792394, lr_dacay is 0.995


Epoch 208:
Total Loss: 0.36245760321617126
Running time: 130.16722106933594
learning rate is 0.00035253382661792394
next epoch lr is 0.0003507711574848343, lr_dacay is 0.995


Epoch 209:
Total Loss: 0.35920387506484985
Running time: 130.40602374076843
learning rate is 0.0003507711574848343
next epoch lr is 0.00034901730169741013, lr_dacay is 0.995


Epoch 210:
Total Loss: 0.42688095569610596
Running time: 130.28736567497253
learning rate is 0.00034901730169741013
next epoch lr is 0.0003472722151889231, lr_dacay is 0.995


Epoch 211:
Total Loss: 0.422952800989151
Running time: 130.07145738601685
learning rate is 0.0003472722151889231
next epoch lr is 0.0003455358541129785, lr_dacay is 0.995


Epoch 212:
Total Loss: 0.32380756735801697
Running time: 130.34410905838013
learning rate is 0.0003455358541129785
next epoch lr is 0.0003438081748424136, lr_dacay is 0.995


Epoch 213:
Total Loss: 0.39955711364746094
Running time: 130.0758113861084
learning rate is 0.0003438081748424136
next epoch lr is 0.0003420891339682015, lr_dacay is 0.995


Epoch 214:
Total Loss: 0.2835214138031006
Running time: 130.19320583343506
learning rate is 0.0003420891339682015
next epoch lr is 0.0003403786882983605, lr_dacay is 0.995


Epoch 215:
Total Loss: 0.3661561608314514
Running time: 130.28125596046448
learning rate is 0.0003403786882983605
next epoch lr is 0.0003386767948568687, lr_dacay is 0.995


Epoch 216:
Total Loss: 0.4775643050670624
Running time: 130.22627139091492
learning rate is 0.0003386767948568687
next epoch lr is 0.00033698341088258437, lr_dacay is 0.995


Epoch 217:
Total Loss: 0.311787873506546
Running time: 130.24220204353333
learning rate is 0.00033698341088258437
next epoch lr is 0.00033529849382817143, lr_dacay is 0.995


Epoch 218:
Total Loss: 0.34389978647232056
Running time: 130.35675740242004
learning rate is 0.00033529849382817143
next epoch lr is 0.00033362200135903056, lr_dacay is 0.995


Epoch 219:
Total Loss: 0.29007774591445923
Running time: 130.15987730026245
learning rate is 0.00033362200135903056
next epoch lr is 0.0003319538913522354, lr_dacay is 0.995


Epoch 220:
Total Loss: 0.38965654373168945
Running time: 130.34794735908508
learning rate is 0.0003319538913522354
next epoch lr is 0.00033029412189547426, lr_dacay is 0.995


Epoch 221:
Total Loss: 0.29232344031333923
Running time: 130.08221173286438
learning rate is 0.00033029412189547426
next epoch lr is 0.0003286426512859969, lr_dacay is 0.995


Epoch 222:
Total Loss: 0.24719873070716858
Running time: 130.22551107406616
learning rate is 0.0003286426512859969
next epoch lr is 0.0003269994380295669, lr_dacay is 0.995


Epoch 223:
Total Loss: 0.3317243158817291
Running time: 130.3037691116333
learning rate is 0.0003269994380295669
next epoch lr is 0.0003253644408394191, lr_dacay is 0.995


Epoch 224:
Total Loss: 0.2515897750854492
Running time: 130.2271466255188
learning rate is 0.0003253644408394191
next epoch lr is 0.000323737618635222, lr_dacay is 0.995


Epoch 225:
Total Loss: 0.4182910919189453
Running time: 130.0510561466217
learning rate is 0.000323737618635222
next epoch lr is 0.00032211893054204585, lr_dacay is 0.995


Epoch 226:
Total Loss: 0.3717063367366791
Running time: 130.41077184677124
learning rate is 0.00032211893054204585
next epoch lr is 0.0003205083358893356, lr_dacay is 0.995


Epoch 227:
Total Loss: 0.2611660659313202
Running time: 130.11720180511475
learning rate is 0.0003205083358893356
next epoch lr is 0.0003189057942098889, lr_dacay is 0.995


Epoch 228:
Total Loss: 0.3259885311126709
Running time: 130.25580644607544
learning rate is 0.0003189057942098889
next epoch lr is 0.00031731126523883944, lr_dacay is 0.995


Epoch 229:
Total Loss: 0.27972352504730225
Running time: 130.46837282180786
learning rate is 0.00031731126523883944
next epoch lr is 0.00031572470891264525, lr_dacay is 0.995


Epoch 230:
Total Loss: 0.33386602997779846
Running time: 130.35853242874146
learning rate is 0.00031572470891264525
next epoch lr is 0.000314146085368082, lr_dacay is 0.995


Epoch 231:
Total Loss: 0.3194229006767273
Running time: 130.39782524108887
learning rate is 0.000314146085368082
next epoch lr is 0.0003125753549412416, lr_dacay is 0.995


Epoch 232:
Total Loss: 0.3021240234375
Running time: 130.061785697937
learning rate is 0.0003125753549412416
next epoch lr is 0.0003110124781665354, lr_dacay is 0.995


Epoch 233:
Total Loss: 0.37932950258255005
Running time: 130.3516342639923
learning rate is 0.0003110124781665354
next epoch lr is 0.00030945741577570273, lr_dacay is 0.995


Epoch 234:
Total Loss: 0.2491312175989151
Running time: 130.32640933990479
learning rate is 0.00030945741577570273
next epoch lr is 0.0003079101286968242, lr_dacay is 0.995


Epoch 235:
Total Loss: 0.3054456412792206
Running time: 130.34440398216248
learning rate is 0.0003079101286968242
next epoch lr is 0.0003063705780533401, lr_dacay is 0.995


Epoch 236:
Total Loss: 0.21780186891555786
Running time: 130.37892508506775
learning rate is 0.0003063705780533401
next epoch lr is 0.0003048387251630734, lr_dacay is 0.995


Epoch 237:
Total Loss: 0.2843732535839081
Running time: 130.27096247673035
learning rate is 0.0003048387251630734
next epoch lr is 0.000303314531537258, lr_dacay is 0.995


Epoch 238:
Total Loss: 0.23278139531612396
Running time: 130.2761538028717
learning rate is 0.000303314531537258
next epoch lr is 0.0003017979588795717, lr_dacay is 0.995


Epoch 239:
Total Loss: 0.28666582703590393
Running time: 130.51598572731018
learning rate is 0.0003017979588795717
next epoch lr is 0.0003002889690851738, lr_dacay is 0.995


Epoch 240:
Total Loss: 0.24350233376026154
Running time: 130.33278846740723
learning rate is 0.0003002889690851738
next epoch lr is 0.000298787524239748, lr_dacay is 0.995


Epoch 241:
Total Loss: 0.22462491691112518
Running time: 130.19909811019897
learning rate is 0.000298787524239748
next epoch lr is 0.0002972935866185492, lr_dacay is 0.995


Epoch 242:
Total Loss: 0.2759333550930023
Running time: 130.44720840454102
learning rate is 0.0002972935866185492
next epoch lr is 0.00029580711868545646, lr_dacay is 0.995


Epoch 243:
Total Loss: 0.273695707321167
Running time: 130.17937421798706
learning rate is 0.00029580711868545646
next epoch lr is 0.0002943280830920292, lr_dacay is 0.995


Epoch 244:
Total Loss: 0.23853707313537598
Running time: 130.1207938194275
learning rate is 0.0002943280830920292
next epoch lr is 0.00029285644267656904, lr_dacay is 0.995


Epoch 245:
Total Loss: 0.31667381525039673
Running time: 130.24718236923218
learning rate is 0.00029285644267656904
next epoch lr is 0.0002913921604631862, lr_dacay is 0.995


Epoch 246:
Total Loss: 0.21875618398189545
Running time: 130.22549653053284
learning rate is 0.0002913921604631862
next epoch lr is 0.00028993519966087026, lr_dacay is 0.995


Epoch 247:
Total Loss: 0.2414301037788391
Running time: 130.31008887290955
learning rate is 0.00028993519966087026
next epoch lr is 0.0002884855236625659, lr_dacay is 0.995


Epoch 248:
Total Loss: 0.23394931852817535
Running time: 130.14538526535034
learning rate is 0.0002884855236625659
next epoch lr is 0.00028704309604425307, lr_dacay is 0.995


Epoch 249:
Total Loss: 0.2683466374874115
Running time: 130.17278695106506
learning rate is 0.00028704309604425307
next epoch lr is 0.0002856078805640318, lr_dacay is 0.995


Epoch 250:
Total Loss: 0.21926534175872803
Running time: 130.13397574424744
learning rate is 0.0002856078805640318
next epoch lr is 0.0002841798411612116, lr_dacay is 0.995


Epoch 251:
Total Loss: 0.20207177102565765
Running time: 130.10613131523132
learning rate is 0.0002841798411612116
next epoch lr is 0.0002827589419554055, lr_dacay is 0.995


Epoch 252:
Total Loss: 0.21907071769237518
Running time: 130.4214267730713
learning rate is 0.0002827589419554055
next epoch lr is 0.0002813451472456285, lr_dacay is 0.995


Epoch 253:
Total Loss: 0.27022600173950195
Running time: 130.33977508544922
learning rate is 0.0002813451472456285
next epoch lr is 0.0002799384215094004, lr_dacay is 0.995


Epoch 254:
Total Loss: 0.21054817736148834
Running time: 130.45809817314148
learning rate is 0.0002799384215094004
next epoch lr is 0.00027853872940185336, lr_dacay is 0.995


Epoch 255:
Total Loss: 0.21581192314624786
Running time: 130.17703080177307
learning rate is 0.00027853872940185336
next epoch lr is 0.0002771460357548441, lr_dacay is 0.995


Epoch 256:
Total Loss: 0.24814088642597198
Running time: 130.25858879089355
learning rate is 0.0002771460357548441
next epoch lr is 0.0002757603055760699, lr_dacay is 0.995


Epoch 257:
Total Loss: 0.1951250284910202
Running time: 130.66810965538025
learning rate is 0.0002757603055760699
next epoch lr is 0.0002743815040481895, lr_dacay is 0.995


Epoch 258:
Total Loss: 0.2098023146390915
Running time: 130.55742359161377
learning rate is 0.0002743815040481895
next epoch lr is 0.00027300959652794857, lr_dacay is 0.995


Epoch 259:
Total Loss: 0.25006574392318726
Running time: 130.30499005317688
learning rate is 0.00027300959652794857
next epoch lr is 0.0002716445485453088, lr_dacay is 0.995


Epoch 260:
Total Loss: 0.21732492744922638
Running time: 130.47150325775146
learning rate is 0.0002716445485453088
next epoch lr is 0.0002702863258025823, lr_dacay is 0.995


Epoch 261:
Total Loss: 0.18394751846790314
Running time: 130.33285450935364
learning rate is 0.0002702863258025823
next epoch lr is 0.00026893489417356936, lr_dacay is 0.995


Epoch 262:
Total Loss: 0.25458937883377075
Running time: 130.47612881660461
learning rate is 0.00026893489417356936
next epoch lr is 0.0002675902197027015, lr_dacay is 0.995


Epoch 263:
Total Loss: 0.2051747888326645
Running time: 130.28200817108154
learning rate is 0.0002675902197027015
next epoch lr is 0.000266252268604188, lr_dacay is 0.995


Epoch 264:
Total Loss: 0.1867293268442154
Running time: 129.882404088974
learning rate is 0.000266252268604188
next epoch lr is 0.0002649210072611671, lr_dacay is 0.995


Epoch 265:
Total Loss: 0.2042757123708725
Running time: 129.9026656150818
learning rate is 0.0002649210072611671
next epoch lr is 0.0002635964022248612, lr_dacay is 0.995


Epoch 266:
Total Loss: 0.23077964782714844
Running time: 130.1048755645752
learning rate is 0.0002635964022248612
next epoch lr is 0.0002622784202137369, lr_dacay is 0.995


Epoch 267:
Total Loss: 0.1997847855091095
Running time: 130.13146471977234
learning rate is 0.0002622784202137369
next epoch lr is 0.00026096702811266825, lr_dacay is 0.995


Epoch 268:
Total Loss: 0.18657270073890686
Running time: 129.87293553352356
learning rate is 0.00026096702811266825
next epoch lr is 0.0002596621929721049, lr_dacay is 0.995


Epoch 269:
Total Loss: 0.1953900307416916
Running time: 129.88103318214417
learning rate is 0.0002596621929721049
next epoch lr is 0.0002583638820072444, lr_dacay is 0.995


Epoch 270:
Total Loss: 0.20122027397155762
Running time: 129.91032195091248
learning rate is 0.0002583638820072444
next epoch lr is 0.00025707206259720813, lr_dacay is 0.995


Epoch 271:
Total Loss: 0.17874345183372498
Running time: 130.21564149856567
learning rate is 0.00025707206259720813
next epoch lr is 0.0002557867022842221, lr_dacay is 0.995


Epoch 272:
Total Loss: 0.2562500536441803
Running time: 130.204270362854
learning rate is 0.0002557867022842221
next epoch lr is 0.00025450776877280096, lr_dacay is 0.995


Epoch 273:
Total Loss: 0.1978570967912674
Running time: 130.31959176063538
learning rate is 0.00025450776877280096
next epoch lr is 0.00025323522992893693, lr_dacay is 0.995


Epoch 274:
Total Loss: 0.16277948021888733
Running time: 130.272531747818
learning rate is 0.00025323522992893693
next epoch lr is 0.00025196905377929227, lr_dacay is 0.995


Epoch 275:
Total Loss: 0.2446986734867096
Running time: 130.40387630462646
learning rate is 0.00025196905377929227
next epoch lr is 0.0002507092085103958, lr_dacay is 0.995


Epoch 276:
Total Loss: 0.1867271512746811
Running time: 130.35117077827454
learning rate is 0.0002507092085103958
next epoch lr is 0.0002494556624678438, lr_dacay is 0.995


Epoch 277:
Total Loss: 0.19946511089801788
Running time: 130.22801399230957
learning rate is 0.0002494556624678438
next epoch lr is 0.0002482083841555046, lr_dacay is 0.995


Epoch 278:
Total Loss: 0.17362074553966522
Running time: 130.2572512626648
learning rate is 0.0002482083841555046
next epoch lr is 0.00024696734223472706, lr_dacay is 0.995


Epoch 279:
Total Loss: 0.2198386937379837
Running time: 130.2322461605072
learning rate is 0.00024696734223472706
next epoch lr is 0.00024573250552355344, lr_dacay is 0.995


Epoch 280:
Total Loss: 0.1953393816947937
Running time: 130.34355401992798
learning rate is 0.00024573250552355344
next epoch lr is 0.00024450384299593567, lr_dacay is 0.995


Epoch 281:
Total Loss: 0.17770548164844513
Running time: 130.29401779174805
learning rate is 0.00024450384299593567
next epoch lr is 0.000243281323780956, lr_dacay is 0.995


Epoch 282:
Total Loss: 0.17611905932426453
Running time: 130.33892369270325
learning rate is 0.000243281323780956
next epoch lr is 0.0002420649171620512, lr_dacay is 0.995


Epoch 283:
Total Loss: 0.19960299134254456
Running time: 130.36831259727478
learning rate is 0.0002420649171620512
next epoch lr is 0.00024085459257624093, lr_dacay is 0.995


Epoch 284:
Total Loss: 0.19388402998447418
Running time: 130.45511174201965
learning rate is 0.00024085459257624093
next epoch lr is 0.00023965031961335973, lr_dacay is 0.995


Epoch 285:
Total Loss: 0.17238399386405945
Running time: 130.39532852172852
learning rate is 0.00023965031961335973
next epoch lr is 0.00023845206801529294, lr_dacay is 0.995


Epoch 286:
Total Loss: 0.16661374270915985
Running time: 130.35822176933289
learning rate is 0.00023845206801529294
next epoch lr is 0.00023725980767521648, lr_dacay is 0.995


Epoch 287:
Total Loss: 0.17680150270462036
Running time: 130.15380191802979
learning rate is 0.00023725980767521648
next epoch lr is 0.00023607350863684038, lr_dacay is 0.995


Epoch 288:
Total Loss: 0.17134864628314972
Running time: 130.34893321990967
learning rate is 0.00023607350863684038
next epoch lr is 0.00023489314109365617, lr_dacay is 0.995


Epoch 289:
Total Loss: 0.18421176075935364
Running time: 130.3250117301941
learning rate is 0.00023489314109365617
next epoch lr is 0.0002337186753881879, lr_dacay is 0.995


Epoch 290:
Total Loss: 0.1929708868265152
Running time: 130.20894932746887
learning rate is 0.0002337186753881879
next epoch lr is 0.00023255008201124696, lr_dacay is 0.995


Epoch 291:
Total Loss: 0.17311695218086243
Running time: 130.43505907058716
learning rate is 0.00023255008201124696
next epoch lr is 0.00023138733160119073, lr_dacay is 0.995


Epoch 292:
Total Loss: 0.20969896018505096
Running time: 130.34200477600098
learning rate is 0.00023138733160119073
next epoch lr is 0.0002302303949431848, lr_dacay is 0.995


Epoch 293:
Total Loss: 0.1648484170436859
Running time: 130.36693239212036
learning rate is 0.0002302303949431848
next epoch lr is 0.00022907924296846886, lr_dacay is 0.995


Epoch 294:
Total Loss: 0.16170558333396912
Running time: 130.26892495155334
learning rate is 0.00022907924296846886
next epoch lr is 0.0002279338467536265, lr_dacay is 0.995


Epoch 295:
Total Loss: 0.1594669371843338
Running time: 130.28719115257263
learning rate is 0.0002279338467536265
next epoch lr is 0.00022679417751985838, lr_dacay is 0.995


Epoch 296:
Total Loss: 0.18084827065467834
Running time: 130.2884063720703
learning rate is 0.00022679417751985838
next epoch lr is 0.00022566020663225908, lr_dacay is 0.995


Epoch 297:
Total Loss: 0.16718634963035583
Running time: 130.28609561920166
learning rate is 0.00022566020663225908
next epoch lr is 0.00022453190559909778, lr_dacay is 0.995


Epoch 298:
Total Loss: 0.14639507234096527
Running time: 130.3137981891632
learning rate is 0.00022453190559909778
next epoch lr is 0.00022340924607110228, lr_dacay is 0.995


Epoch 299:
Total Loss: 0.1595940887928009
Running time: 130.50518226623535
learning rate is 0.00022340924607110228
next epoch lr is 0.00022229219984074678, lr_dacay is 0.995


